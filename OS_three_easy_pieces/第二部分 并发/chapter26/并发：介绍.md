##并发：介绍
目前为止，我们已经看过了OS提供的基本抽象的发展历程。我们已经看到了如何把单个物理CPU转换为多个 __虚拟CPU__，从而使OS可以提供一个在同一时刻运行多个程序的幻象。我们也已经看到对每个进程都构建一个大的，私有的 __虚拟内存__ 幻象，这个 __地址空间__ 的抽象让每个程序的行为好像它有自己的内存，而事实上OS正在秘密的跨物理内存(有时候还有硬盘)多路复用地址空间。

在这个文章中，我们对单个运行进程介绍一个新的抽象：那就是 __thread__。在程序内部不像我们对只有一个单独执行体点的经典看法(例如，只有唯一一个PC，指令从这里获取并执行)，一个 __多线程__ 的程序超过一个执行点(例如，多个PC，每个都可以获取指令并执行)。可能另一个思考方式是认为每个线程和独立的进程很类似，除了一个不同点：他们 _share_ 相同的地址空间因此可以访问相同的数据。

单个线程的状态非常类似单个进程。它有一个程序计数器(PC)，用来跟踪程序正在从哪里取指令。每个线程还有自己私有的寄存器集合用来计算；因此，如果有两个线程运行在一个处理器器上，当发生从一个运行线程(T1)切换到另一个运行线程(T2)，就需要执行 __上下文切换(context switch)__。线程之间的上下文切换很类似与进程的上下文切换，因为T1的寄存器状态必须要被保存下来而T2的寄存器状态要在T2运行前恢复。在用进程时，我们把状态存放到 __进程控制块(PCB)__；现在，我们需要一个或多个 __线程控制块(thread control blocks TCBs)__ 用以存放进程中每个线程的状态。这里有一个主要不同点，也即，和进程上下文切换相比较，线程在发生上下文切换时地址控制保持一样(例如，没有必要切换我们正在使用的页表)。

线程和进程所关心的另一个主要不同之处是栈。在我们典型进程(我们现在叫做 __单线程(single-threaded)__ 进程)地址空间例子中，只有一个栈，通常位于地址空间底部(图26_1，左侧)。

![Figure26_1.png "单线程和多线程地址空间"](Figure26_1.png "单线程和多线程地址空间")

然而，在多线程进程中，每个线程是独立运行的，并且它当然可能会调用各种例程做任何它正在做的工作。不想地址空间只有单一栈，这里每个线程都有一个栈。假设我们的多线程进程有两个线程；地址空间就有所不同(Figure26_2，右侧)。

在这个图中，你可以看到进程地址空间散布着两个栈。因此，任何栈分配变量，形参和其它我们放在栈上的东西都会放置在我们称作 __thread-local__ 存储中，例如，栈相关的线程。

你可能注意到这种方式是如何毁掉了我们美丽的地址空间布局。之前，栈和堆可以独立的增长，只有当你用完地址空间时才会导致问题。这里，我们不再有这么好的场景了。幸运的是，这通常是OK的，因为栈基本上不会过大(只有程序使用了很重的递归才会有异常)。

###26.1 为什么使用线程？
在涉及了解线程细节和你可能在编写多线程程序会遇到的某些问题之前，让我们先检查一个简单的问题。我们究竟为啥使用线程？

事实上，你使用线程有两个主要原因。第一个很简单：__并行(parallelism)__。想象你正在编写一个程序，它操作一个很大很大的数组，例如，把两个数组加在一起，或者给一个数组每个元素加一个值。如果你只运行在一个进程上面，任务就很直接：执行每一步操作然后结束。但是，如果你在有着多个处理器的系统上执行这个程序，通过让每个处理器执行部分工作，你就有相当高可能性加速这个进程了。那种把标准 __单线程__ 程序转换为在多核CPU做这些工作的任务叫做 __并行化(parallelization)__，在每个CPU上使用线程做这种工作是自然和典型的方式让程序在现代硬件上运行的更快。

第二个原因就有点微妙了：为了避免由于慢I/O阻塞程序进行。想象你正在编写一个执行不同类型I/O的程序：要么为了一个显式硬盘I/O完成或者甚至是(隐式)为了完成一个页错误而等待发送或接收消息，不是单纯的等待，你的程序可能希望还要完成其它事情，包括利用CPU完成其它计算，甚至是发出更多的I/O请求。使用线程是避免阻塞的一个自然方式；当你程序中一个线程在等待(因为等待I/O被阻塞)，CPU调度器可以切换到其它线程，这些线程准备运行做有用的事情。通过在单个进程 _包含(within)_ 其它活动(activities)，线程化让I/O __重叠(overlap)__ 变得可能，这很类似 __多程序(multiprogramming)__ 为多个进程在 _跨_ 程序做的那样；结果是，很多现代基于服务器的应用(web server，数据库管理系统，和其他类似的东西)在它们的实现中都是用了线程。

当然，在上面提的任意情形，你可以使用多 _进程_ 替换线程。但是，线程共享地址空间，从而让共享数据变得简单，因此多线程是构建这类程序的自然选择。多进程对于逻辑上分离的任务是更好的选择，这里在内存中数据结构的共享需求很小。

###26.2 例子：线程创建
让我们看一些细节。假设我们想要运行一个创建了两个线程的程序，每个线程执行某种独立的工作，在这个场景中是打印"A"或者"B"。代码如下：
```C
#include <stdio.h>
#include <assert.h>
#include <pthread.h>

void *mythread(void *arg) {
    printf("%s\n", (char *) arg);
    return NULL;
}
int main(int argc, char *argv[]) {
    pthread_t p1, p2;
    int rc;
    printf("main: begin\n");
    rc = pthread_create(&p1, NULL, mythread, "A"); assert(rc == 0);
    rc = pthread_create(&p2, NULL, mythread, "B"); assert(rc == 0);
    // join waits for the threads to finish
    rc = pthread_join(p1, NULL); assert(rc == 0);
    rc = pthread_join(p2, NULL); assert(rc == 0);
    printf("main: end\n");
    return 0;
}
```
这个主程序创建了两个线程，每个进程将会运行`mythread()`函数，通过使用不同的实参(字符串`A`或者`B`)。一旦线程被创建，他可可能会立即运行(依赖于是调度器)；另外的，他可能会是“准备”而不是“运行”状态从而不能运行。当然，在多处理器上，这些线程可能同时运行，但我们现在不用关系这个可能性。

在创建两个线程后(我们称之为T1和T2)，主线程调用`pthread_join()`，这个方法会等待特定的线程完成。主线程执行了两次，确保了T1和T2将在最后允许主线程再次运行前运行并完成；当它完成，他将会打印"main:end"然后推出。总的来说，在这次运行期有三个线程运行：main线程，T1和T2。

让我们检查一下这个程序可能的执行顺序。在执行图(Figure26_3)中，时间按照箭头方向向下增长，每行显示了不同的线程在什么时候执行(主线程，线程1或者线程2)。

![Figure26_3.png "线程跟踪(1)"](Figure26_3.png "线程跟踪(1)")

记住，这个顺序并不只是唯一的可能顺序。事实上，给定一个指令序列，是有些不同的，这依赖于在给定时间调度器决定运行哪个线程。例如，一旦线程被创建，它可能会立即运行，从而会导致如图26_4的执行顺序。

![Figure26_4.png "线程跟踪(2)"](Figure26_4.png "线程跟踪(2)")

我们甚至也可能看到"B"在"A"之前打印，如果，例如，尽管线程1比线程2先创建，调度器决定先运行线程2；没有理由假设先创建的线程会先运行。图26_5显示了这个最终执行顺序，也就是线程2比线程1先完成自己的事情。

![Figure26_5.png "线程跟踪(3)"](Figure26_5.png "线程跟踪(3)")

你也有可能看到，考虑线程创建的一个方式是它有点想函数调用；然而，跟先执行函数然后返回到调用者不一样，系统会为被调用的例程创建一个新的执行线程，它和调用者的运行是独立的，可能从创建之后它要早于调用这返回前执行，也可能很晚之后执行。下一个谁运行是由OS __调度器__ 决定的，尽管调度器很可能会实现某些有意义的算法，然而很难在给定的时刻知道哪个线程将会运行。

你还可能从这个例子中分辨，线程让生活变得复杂了：已经很难分辨什么线程将在何时运行！计算机在没有并发时已经足够难理解了。不幸的是，有了并发，它变得更糟糕，非常糟糕。

### 为什么变得更糟糕：共享数据
在显示：1.线程如何创建；2.依赖于调度器决定如何运行线程，线程会按照怎样顺序运行这两种情况下，我们上面展示的简单线程例子是很有用的。他没有显示给你的是，线程在访问共享数据时是如何交互的。

让我们想象一个简单的例子，两个线程希望更新一个全局共享变量。我们将研究的代码如下：
```C
#include <stdio.h>
#include <pthread.h>
#include "mythreads.h"
static volatile int counter = 0;
//
// mythread()
//
// Simply adds 1 to counter repeatedly, in a loop
// No, this is not how you would add 10,000,000 to
// a counter, but it shows the problem nicely.
//
void *mythread(void *arg)
{
    printf("%s: begin\n", (char *)arg);
    int i;
    for (i = 0; i < 1e7; i++)
    {
        counter = counter + 1;
    }
    printf("%s: done\n", (char *)arg);
    return NULL;
}

//
// main()
//
// Just launches two threads (pthread_create)
// and then waits for them (pthread_join)
//
int main(int argc, char *argv[])
{
    pthread_t p1, p2;
    printf("main: begin (counter = %d)\n", counter);
    Pthread_create(&p1, NULL, mythread, "A");
    Pthread_create(&p2, NULL, mythread, "B");

    // join waits for the threads to finish
    Pthread_join(p1, NULL);
    Pthread_join(p2, NULL);
    printf("main: done with both (counter = %d)\n", counter);
    return 0;
}
```
这里这个代码有几点要注意。首先，根据Stevens的建议，我们把线程创建和jion例程包装起来，为了简化失败时退出；对于和这个例子中一样简单的程序，我们希望至少注意到发成了错误(如果确实发生了)，但是不需要做任何更智能的操作了(例如，我们仅仅只是退出)，因此，`Pthread_create()`只是简单的调用`pthread_create()`并确保返回值为0；如果不是，`Pthread_create()`就打印一个信息然后退出。

第二，对于工作线程，不是使用两个独立的函数体，我们只用一个代码片段，传递给线程参数(这个例子中是一个字符串)，这样我们就可以让每个线程在打印自己的信息前加上一个不同信息。

最后，也是最重要的，我们现在看看每个工作线程想做什么：给共享变量`counter`增加一个数，然后循环做一千万次。想要的结果是：20,000,000。

现在我们编译运行这个程序，看看它的行为是什么样子的。有时候，每件事都如我们期望的那样：
```sh
prompt> gcc -o main main.c -Wall -pthread
prompt> ./main
main: begin (counter = 0)
A: begin
B: begin
A: done
B: done
main: done with both (counter = 20000000)
```
不幸的是，当我们运行这个代码，尽管是在单处理器，我们也没有取到想要的结果。有时候，我们得到：
```sh
prompt> ./main
main: begin (counter = 0)
A: begin
B: begin
A: done
B: done
main: done with both (counter = 19345221)
```
多次运行，事情变得更加疯狂。毕竟，难道计算机不应该产生 __确定的__ 结果么，正如你被教导的那样？可能是你的教授欺骗你了？
```sh
prompt> ./main
main: begin (counter = 0)
A: begin
B: begin
A: done
B: done
main: done with both (counter = 19221041)
```
每次运行的结果不仅是错误的，还是各个不同！留下一个大问题：为什么会发生这些？

###26.4 问题的核心：不受控的调度
为了理解这些为什么会发生，我们必须理解编译器为了更新`counter`生成的代码序列。在这个案例里，我们只是简单的给`counter`加一个数(1)。完成这样一个事情的代码序列如下(x86):
```asm
mov 0x8049a1c, %eax
add $0x1, %eax
mov %eax, 0x8049a1c
```
>###tip：了解并使用你的工具
>你应该总是学习那些可以帮助你编写，调试和理解计算机系统的新工具。这里，我们用的是 __反汇编器(disassembler)__。当你一个可执行文件上运行反汇编器，他显示了组成程序的汇编指令。例如，如果我们希望理解更新一个计数器的底层代码(就像我们例子)，我们运行`objdump`(Linux)看看汇编代码：
```sh
prompt>objdump -d main
```
>这样就产生了程序所有指令的列表，设置了干净的标签(具体就是如果你编译时设置了`-g`标志)，包含了程序的符号信息。`objdump`程序只是众多你需要学会使用的工具之一；还有调试器`gdb`，内存分析器`valgrind`和`purify`，当然编译器本身是另一个你需要花费时间了解跟多的；你对正在使用的工具有更好理解，你就能力构建更好的系统。

这个例子假设变量`counter`位于地址`0x8049a1c`处。在这个三指令序列里，x86`mov`指令首先用来在内存指定的地址获取值放入到寄存器`eax`中。然后，执行`add`，给`eax`寄存器中的值加1(0x1)，最后，`eax`的内容被重新存回到内存同一个地址中。

让我们假设两个线程中的一个(线程1)进入的这个代码区域，他将要给`counter`加一。他加载`counter`的值(让我们假设开始是50)到寄存器`eax`。因此对于线程1来说`eax=50`。然后加一到寄存器；因此`eax=51`。现在，某些不好事情发生了：一个定时器发生了；因此，OS保存当前运行线程的状态(它的PC，它的寄存器包括`eax`，等等)，到线程TCB。

现在某些更遭发生了：线程2便选择执行，他进入了同样的代码段。他也执行了第一个指令，获取了`counter`的值并放入它的寄存器`eax`(记住：每个线程在运行时都由自己的寄存器；通过上下文切换代码对寄存器的保存和恢复，这些寄存器被 __虚拟化__ 了)。在这个时候，`counter`的值依旧是50，因此线程2就有`eax=50`。让我们假设线程2执行了接下来的两个指令，给`eax`加一(`eax=51`)，然后保存`eax`的内容到`counter`(地址`0x8049a1c`)。因此，全局变量`counter`现在的值是51。

最后，另一个上下文切换发生，线程1恢复执行。回忆一下，它刚刚执行了`mov`和`add`，然后将要执行最后的`mov`指令。此时的`eax=51`。因此，最后的指令`mov`执行，保存值到内存；`counter`又一次被设置为51。

简化一下，这里发生的是：`counter`被代码加了两次，但是`counter`(初始值是50)值只等于51。这个程序一个“正确”的版本是要`counter`的结果等于52。

让我们看看更详细的执行跟踪来更好的理解问题。假设，对于这个例子，上述的代码加载在内存地址100，类似如下的序列(记住这些你用的是美化后，类RISC指令集：x86是变长指令集；`mov`指令占据内存5个字节，而`add`只用3个字节)：
```asm
100 mov 0x8049a1c, %eax
105 add $0x1, %eax
108 mov %eax, 0x8049a1c
```
根据这些假设，图26_7显示了发生了什么。假设`counter`初始值是50，这个例子的跟踪路径确保了你理解将要发生什么。

![Figure26_7.png "问题：近距离且个人的"](Figure26_7.png "近距离且个人的")

