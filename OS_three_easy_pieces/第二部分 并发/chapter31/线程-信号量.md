## 信号量
我们现在知道了，我们需要锁和条件变量一起解决很大范围内相关有趣的并发问题。早年间最开始意识到这个的那些人之一是Edsger Dijkstra(尽管很难知道确切的历史)，他以很多其他事情著名，例如图理论中他的著名最短路径算法，名为"goto被认为是有害的"(多么伟大的标题)一篇关于结构化编程的早期论战文章，以及，这里我们将要学习的理论，一个被叫做 __信号量(semaphore)__ 同步原语介绍。事实上，Dijkstra 和其同事发明的信号量是作为与并发相关的唯一原语；正如你将看到的，我们可以把信号量既用作锁也用作条件变量。
>####症结：如何使用信号量
>我们要怎么使用信号量而不是锁和条件变量？信号量的定义是什么？什么是二元信号量？使用锁和条件变量直接构造信号量可行么？使用信号量构造锁和条件变量呢？
###31.1 信号量：定义
信号量是一个对象它包含一个整数值我们可以使用两个例程维护这个整数值；在POSIX标准里，这些例程是`sem_wait()`和`sem_post()`[<sub id="content1">1</sub>](#1)。因为信号量的初始值决定了它的行为，我们必须首先以某个值初始化它，正如代码片段31.1那样。
```c
#include <semaphore.h>
sem_t s;
sem_init(&s, 0, 1);
```
__代码片段31.1初始化信号量__

在上面的代码中，我们声明了一个信号量并初始化它的值为1，通过在第三个实参传入1实现。`sem_init()`第二个参数在我们将看到的所有例子里都被设置为0；它表示在同一个进程里面信号量在线程中是共享的。关于信号量的其它使用细节参见man手册(即，信号量是如何跨进程使用来同步访问)，这就需要在第二个参数传入不同的值。

信号量初始化之后，我们可以调用`sem_wait()`和`sem_post()`函数与之交互。它们的行为如代码片段31.2所示：
```c
int sem_wait(sem_t *s)
{
    decrement the value of semaphore s by one
        wait if value of semaphore s is negative
}

int sem_post(sem_t *s)
{
    increment the value of semaphore s by one if there are one or more threads waiting, wake one
}
```
__代码31.2 信号量：Wait和Post定义__

现在，我们不关心这些例程的实现，当然显然还是需要一些关心，在使用多线程调用`sem_wait()`和`sem_post()`时，为了管理关键区那有显著的要求。我们现在将只关心如何使用这些原语，稍后我们将会讨论如何构建它们。

这里我们应该讨论这两个接口几个显著的方面。首先，我们可以看到`sem_wait()`要么会立刻返回(因为在我们调用时信号量的值是1或者比1更大)，或者它会导致调用者暂停执行等待后续的post。当然，多个调用线程可能会都会调用`sem_wait()`，所以都需要入队等待被唤醒。

第二，我们可以看到`sem_post()`没有像`sem_wait()`那样等待去持有某些特定条件(这句话的意思是不像`sem_wait()`那样需要判断信号量的值是不是大于0)。相反，他就是简单的增加信号量的值然后如果有线程等待被唤醒，就唤醒其中一个。

第三，信号量的值，当变成负数时，就和等待线程个数相等。尽管这个值通常不会被信号量的使用者看到，这个不变量是值得了解并且可能帮助你记住信号量的工作方式。

(目前)不用担心可能会在信号量内部发生的竟态条件；先假设他们执行的操作是原子的。我们将很快使用锁和条件变量来完成这些。

###31.2 二元信号量(锁)
我们先准备使用信号量。我们首先用于一个我们熟悉的情况：使用信号量实现锁。参见代码片段31.3，在里面你可以看到我们就是在关键区周围使用`sem_wait()`/`sem_post()`对。让这个工作的关键点就是信号量`m`的初始值(代码中被初始化为X)这个X应该是多少？
```c
sem_t m;
sem_init(&m, 0, X); // initialize to X; what should X be?
sem_wait(&m);
// critical section here
sem_post(&m);
```
__代码片段31.3 二元信号量(也就是锁)__

回头看一下`sem_wait()`和`sem_post()`例程的定义，我们可以看到这个初始值应该设置为1。

为了讲的更明白些，让我们想象一个有着两个线程的场景。第一个线程(线程0)调用`sem_wait()`；它首先会对信号量的值减一，改成0。然后，如果值小于0，线程0就会一直等待。因为值为0，`sem_wait()`就会返回然后调用线程将会继续(注：这里这句话应该是对上面小于等于0线程等待的解释)；线程0现在就可以自由的进入关键区。如果在线程0位于关键区的时候没有其它线程试图获取锁，当线程0调用`sem_post()`，它会简单的把信号量的值恢复为1(并且没有唤醒一个等待线程，因为没有等待线程)。图31_4显示了这个场景的跟踪过程。

![图31_4.png "线程跟踪：单个线程使用信号量"](#figure31_4.png "线程跟踪：单个线程使用信号量")

更有趣的情况发生在当线程0"持有锁"(例如，它调用了`sem_wait()`但是还没有调用`sem_post()`)，另一个线程(线程1)(通过调用`sem_wait()`)试图进入关键区。在这种场景下，线程1将会把信号量的值减为-1，因此会等待(让自己睡眠然后放弃(relinquish放弃，尤指不情愿的)处理器)。当线程0再次运行，他最终将会调用`sem_post()`，增加信号量的值回到0，然后唤醒等待中的线程(线程1)，这个线程可以获取到锁。当线程1结束，他将会再一次的对信号量的值加一，再一次的恢复为1。

图31_5显示了这个例子的跟踪情况。除了线程动作以外，这个图还显示了每个线程的 __调度器状态(scheduler state)__：运行(这个线程在运行)，准备(线程可以运行带没有运行)和睡眠(线程被阻塞)。注意线程1在试图获取已经被持有的锁的时候进入睡眠状态；只有当线程0再次运行线程1才能被唤醒然后有再次运行的可能。

![图31_5.png "线程跟踪：两个线程使用一个信号量"](#figure31_5.png "线程跟踪：两个线程使用一个信号量")

如果你想要在你的例子里让它工作，试着在多个线程排队等待锁的场景下使用。在这样的追踪路径下信号量的值是如何变化的？

到此我们就可以使用信号量作为锁了。因为锁只有两个状态(被持有和没有被持有)，我们有时候把用作锁的信号量称为 __二元信号量(binary semaphore)__。注意如果你只按照这个二元方式使用信号量，它可以用一种比这里呈现的泛化版本信号量更简单的方法实现信号量。

###31.3 用于排序的信号量
信号量对于在并发编程中排序事件很有用。例如，一个线程可能希望等待一个列表变为非空，从而它可以从中删除一个元素。在这种使用模式里面，我们通常找到一个线程 _等待_ 某个事情发生，然后另一个线程让这些事发生然后 _发信号signaling_ 事情发生了，从而唤醒等待的线程。从而我们就在使用信号量作为 __排序(ordering)__ 原语(类似于我们之前对 __条件变量__ 的使用)。

一个简单的例子如下。想象有一个线程创建另一个线程然后想要等待它完成执行(代码片段31_6)。
```c
sem_t s;

void *child(void *arg)
{
    printf("child\n");
    sem_post(&s); // signal here: child is done
    return NULL;
}

int main(int argc, char *argv[])
{
    sem_init(&s, 0, X); // what should X be?
    printf("parent: begin\n");
    pthread_t c;
    Pthread_create(&c, NULL, child, NULL);
    sem_wait(&s); // wait here for child
    printf("parent: end\n");
    return 0;
}
```
__代码片段：父线程等待子线程__

当程序运行，我们可以看到如下执行结果：
```console
parent: begin
child
parent: end
```

这里问题是如果使用信号量达到这个效果：事实证明，答案相对容易理解。正如你可以从代码中看到，父线程简单的调用`sem_wait()`而子线程`sem_post()`等待子线程结束执行这一条件变为真。然而，这引发了一个问题：信号量的初始值应该是多少？

答案当然就是信号量的值被设置为0。这里要考虑两种情况。首先，让我们假设父线程创建子线程后子线程还没有运行(例如，它处于准备队列中但是没有运行)。在这种情况下(图31_7)，父线程将会在子线程调用`sem_post()`之前调用`sem_wait()`；我们想要父线程等待子线程运行。这种情况发生的问题方式就是信号量的值小于0；因此，0就是初始值。父线程运行，对信号量减一(变为-1)，然后等待(睡眠)。当子线程最终运行，它会调用`sem_post()`，对信号量的值加一变成0，然后唤醒父线程，然后父线程从`sem_wait()`中返回结束程序。

![图31_7 "线程追踪：父线程等待子线程(情况1)"](#figure31_7 "线程追踪：父线程等待子线程(情况1)")

第二种情况(图31_8)发生在子线程在父线程有机会调用`sem_wait()`前完成。在这种情况下，子线程将会先调用`sem_post()`，因此信号量的值从0变成了1。当父线程有机会运行，它会调用`sem_wait()`然后发现信号量的值是1，然后父线程将会对值减一(变为0)然后不用等待就从`sem_wait()`返回，然后达成所要的效果。
>####附注：设置信号量的值
>现在我们已经看到了两个初始化信号量的值。在第一个情况，我们这是信号量的值为一从而把信号量当作锁；在第二个场景里，设置值为0，从而用信号量来排序。所以，初始化信号量的通用规则是什么呢？
>
>思考这个问题有一个简单的方式，多亏Perry Kivokowitz，就是考虑你在你初始化后立即要暴露出来(give away)的资源数量。对于锁，它是1，因为你将要在初始化之后立即有一个锁可以被锁(被暴露)。对于排序的情况，它是0，因为在开始的时候没有只要被暴露出来；只有当子线程完成时，资源才被创建，在这个时刻，值被加一。在未来思考信号量问题的时候请尝试这个方式，你可看看有没有帮助。
###31.4 生产者/消费者(有界buffer)问题
本章下一个我们要解决的问题是所谓的 __生产者/消费者问题__，有时候也叫做 __有界buffer(bounded buffer)__ 问题。这个问题在前面的条件变量的章节有详细描述；看那里了解细节。
####第一次 尝试
我们第一次尝试解决这个问题引入两个信号量，`emtry`和`full`，线程使用它们分别标识一个buffer条目是空的还是被填充了。put和get例程在代码片段31_9，我们尝试解决生产者消费者问题的代码在代码片段31_10。
```c
int buffer[MAX];
int fill = 0;
int use = 0;

void put(int value)
{
    buffer[fill] = value;    // Line F1
    fill = (fill + 1) % MAX; // Line F2
}

int get()
{
    int tmp = buffer[use]; // Line G1
    use = (use + 1) % MAX; // Line G2
    return tmp;
}
```
__代码片段31_9：Put和Get例程__

```c
sem_t empty;
sem_t full;

void *producer(void *arg)
{
    int i;
    for (i = 0; i < loops; i++)
    {
        sem_wait(&empty); // Line P1
        put(i);           // Line P2
        sem_post(&full);  // Line P3
    }
}

void *consumer(void *arg)
{
    int i, tmp = 0;
    while (tmp != -1)
    {
        sem_wait(&full);  // Line C1
        tmp = get();      // Line C2
        sem_post(&empty); // Line C3
        printf("%d\n", tmp);
    }
}

int main(int argc, char *argv[])
{
    // ...
    sem_init(&empty, 0, MAX); // MAX are empty
    sem_init(&full, 0, 0);    // 0 are full
    // ...
}
```
__代码片段31_10：增加满和空条件__
在这个例子里，生产者首先等待buffer变空从而把数据放到里面，然后消费者类似的在使用buffer的数据前等待buffer变满。让我们先想象`MAX=1`(数组里面只有一个buffer)，看看它是否可以工作。

然后在想象有两个线程，一个生产者一个消费者。让我们检查一个在单CPU上特殊的场景。假设消费者先运行。这样，消费者将会命中代码片段的C1行，调用`sem_wait(&full)`。因为`full`的初始化值是0，这个调用会对`full`减一(变成-1)，阻塞消费者，然后等待另外的线程在`full`调用`sem_post()`，就想想要的那样。

假设生产者然后运行。它会命中行P1，然后调用`sem_wait(&empty)`例程。不像消费者，生产者将会继续通过这一行，因为`empty`被初始化为值`MAX`(在这个情况下是1)。因此，`empty`将会减一变成0然后生产者建辉把一个数据放入到buffer的第一个条目里(P2行)。然后消费者会继续到P3然后调用`sem_post(&full)`，把`full`信号量的值从-1改为0然后唤醒消费者(例如，把它从阻塞移动到准备)。

在这个例子里，会发生两种情况中的一种。如果消费者继续运行，它会循环然后再次命中P1行。然而，这一次它会阻塞，因为`empty`信号量的值是0。如果消费者被中断了，消费者开始运行，它会从`sem_wait(&full)`返回(C1行)，发现buffer是满的，然后消费它。在这任意一种情况，我们都达到了想要的效果。

你可以用更多的线程试试这个例子(例如多个生产者和多个消费者)。他应该依旧可以工作。

让我们想一下`MAX`比1大(假如说是`MAX=10`)。对于这个例子，让我们假设有多个生产者和多个消费者。我们现在有了一个问题：竟态条件。你可以找到哪里会发生么？(花点时间找一下)如果你不能找到，给你一个提示：仔细看看`put()`和`get()`的代码。

####一个方案：添加互斥
正如你看到的，我们这里忘记了 _互斥_。填充一个buffer和给buffer索引加一是关键区，然后必须要被仔细守护。所以让我们用我们的朋友二元信号量添加一些锁。代码31_11显示了我们的尝试。
```c
void *producer(void *arg)
{
    int i;
    for (i = 0; i < loops; i++)
    {
        sem_wait(&mutex); // Line P0 (NEW LINE)
        sem_wait(&empty); // Line P1
        put(i);           // Line P2
        sem_post(&full);  // Line P3
        sem_post(&mutex); // Line P4 (NEW LINE)
    }
}

void *consumer(void *arg)
{
    int i;
    for (i = 0; i < loops; i++)
    {
        sem_wait(&mutex); // Line C0 (NEW LINE)
        sem_wait(&full);  // Line C1
        int tmp = get();  // Line C2
        sem_post(&empty); // Line C3
        sem_post(&mutex); // Line C4 (NEW LINE)
        printf("%d\n", tmp);
    }
}
```
__代码片段31_11：添加互斥(不正确的方式)__

现在让我们在整个代码的`put()/get()`部分周围增加一些锁，但是它不能工作。为什么？死锁。为什么会发生死锁？花一点时间考虑下；试着找一个死锁会发生的例子。对于程序来说什么样的步骤序列一定会发生死锁？
####避免死锁
OK，现在你找到了，这里是答案。想象两个线程，一个消费者一个生产者。消费者首先运行。它获取到了互斥锁(C0行)，然后调用`sem_wait()`在满的信号量(C1行)；因为还没有数据，这个调用导致消费者阻塞然后让出CPU；更重要的是，这个时候消费者始终持有锁。

生产者然后运行。它要产生数据然后如果它可以运行，它将会唤醒消费者线程然后所有都很好。不幸的是，他首先会调用`sem_wait()`在这个二元互斥信号量上(P0行)。锁已经被持有了。因此，生产者现在也阻塞等待。

这里有一个简单的循环。消费者 _持有_ 互斥锁然后 _等待_ 这个某个线程发送full信号。消费者可以 _发送_ full信号但是在 _等待_ 这个互斥锁。因此，消费者和生产者都阻塞在等待对方：一个典型的死锁。
#### 至少，可以工作的方案
为了解决这个问题，我们只需要减少锁的区域。代码片段31_12显示了正确的做法。就像你看到的，我们只是把对互斥锁的请求和释放移动到关键区周围；满和空的等待和唤醒代码留在外面[<sup id="content2">2</sup>](#3)。结果就是一个简单可工作的有界buffer，一个在多线程变成里面常用的模式。现在理解它，以后使用它。以后几年你将会感谢我。或者至少，在期末测验或者工作面试出现同样问题时你会感谢我。
```c
void *producer(void *arg)
{
    int i;
    for (i = 0; i < loops; i++)
    {
        sem_wait(&empty); // Line P1
        sem_wait(&mutex); // Line P1.5 (MUTEX HERE)
        put(i);           // Line P2
        sem_post(&mutex); // Line P2.5 (AND HERE)
        sem_post(&full);  // Line P3
    }
}

void *consumer(void *arg)
{
    int i;
    for (i = 0; i < loops; i++)
    {
        sem_wait(&full);  // Line C1
        sem_wait(&mutex); // Line C1.5 (MUTEX HERE)
        int tmp = get();  // Line C2
        sem_post(&mutex); // Line C2.5 (AND HERE)
        sem_post(&empty); // Line C3
        printf("%d\n", tmp);
    }
}
```
__代码片段31_12:增加互斥(正确的方式)__

###31.5 读写锁
另一个经典问题来自于(stem)对更加灵活的锁定原语(这个原语承认了不同数据结构访问需要请求不同类型的锁定方式)的渴望。例如，想象有一些并发链表操作；包括插入和简单的查找。当插入修改了链表的状态(从而传统的关键区就有意义了)，查找只是简单的读取数据结构；只要我们可以保证没有插入正在运行，我们可以允许多个查找同时并发执行。我们将要开发支持这种情况的特殊类型锁就是 __读写锁(reader-writer lock)__。参看代码片段31_13查看这个锁的实现：
```c
typedef struct _rwlock_t
{
    sem_t lock;      // binary semaphore (basic lock)
    sem_t writelock; // allow ONE writer/MANY readers
    int readers;     // #readers in critical section
} rwlock_t;

void rwlock_init(rwlock_t *rw)
{
    rw->readers = 0;
    sem_init(&rw->lock, 0, 1);
    sem_init(&rw->writelock, 0, 1);
}

void rwlock_acquire_readlock(rwlock_t *rw)
{
    sem_wait(&rw->lock);
    rw->readers++;
    if (rw->readers == 1) // first reader gets writelock
        sem_wait(&rw->writelock);
    sem_post(&rw->lock);
}

void rwlock_release_readlock(rwlock_t *rw)
{
    sem_wait(&rw->lock);
    rw->readers--;
    if (rw->readers == 0) // last reader lets it go
        sem_post(&rw->writelock);
    sem_post(&rw->lock);
}

void rwlock_acquire_writelock(rwlock_t *rw)
{
    sem_wait(&rw->writelock);
}

void rwlock_release_writelock(rwlock_t *rw)
{
    sem_post(&rw->writelock);
}
```
__代码片段31_13:简单的读写锁__

这个代码很简单。如果某个线程想要修改我们讨论的数据结构，他就应该调用新的同步操作对:`rwlock_acquire_writelock()`获取写锁，而`rwlock_release_writelock()`，释放锁。内部就是使用`writelock`信号量确保只有以单个写线程可以请求锁从而进入关键区并更新讨论的数据结构。

跟有趣的是获取和释放读锁的例程对。当请求一个读锁，读线程首先请求`lock`然后对`reader`加一从而跟踪有多少读线程进入了数据结构内。当第一个读线程获取锁时，重要的步骤发生在`rwlock_acquire_readlock()`内，在这种情况下，读线程通过调用`sem_wait()`在`wirtelock`信号量上也请求了写锁，然后通过调用`sem_post()`释放了这个`lock`。

因此，一旦读锁获取了一个读锁，更多的读线程将会也会允许读锁；然而，任何想要获取写锁的线程将一直等待知道所有的读线程完成；只有最后一个线程从关键区退出后调用在"writelock"上`sem_post()`然后确保一个等待的写线程获取锁。

这个方式可以(按照期望的)工作，但是有几个缺点，特别是缺乏公平性。具体地说，相对度线程它很容易饿死写线程。对于这个问题有更优雅的解决方案存在；可能你可以想到一个更好的实现方式？提示：想一下你需要怎么做才能防止当一个写线程在等待时有更多的读线程进入锁。

最后，需要注意到读写锁应该慎重使用。它们通常会增加更多负担(特别是有这个更复杂的实现)，因此跟仅仅使用简单快速的锁定原语相比较它们不是以提升性能为终点的。另外，它们再一次显示了我们如何以一个有趣且有用的方式使用信号量。
>#### tip：简单且愚蠢可以更好(Hill定律)
>你永远不应该低估这句话：简单愚蠢的方式可以是最好的方式。使用锁，有时候是简单的自旋锁可以工作的最好，因为它容易实现且很快。尽管类似于读写锁这些东西听起来很酷，它们很复杂，而复杂意味着慢。因此，总是先尝试简单愚蠢的方式。
>
>这个极其简单易懂的想法在很多地方都可以找到。一个早期的来源是Mark Hill关于研究如何设计CPU缓存的论文。Hill发现简单的直接映射(direct-mapped)缓存比高级的组相关(set-associative)设计工作的更好(一个原因是在缓存过程中，更简单的设计保证了更快的查找)。因此Hill简洁的总结了他的工作:"大而蠢更好"。因此我们成这个类似的建议为 __Hill's Law__。

###31.6 哲学家进餐问题
由Dijkstra提出并解决的一个最著名的并发问题叫做 __哲学家进餐问题__。这个问题之所以著名因为它很有趣；但是它的实用性很低。无论怎样，他的名望让它入选了本章；事实上，你可能会在面试的时候被问道，那么如果你不会那个问题而没有得到工作你就会讨厌你的OS教授。

这个问题的基本步骤是这样的(图31_14)：假设有5个哲学家围着一个桌子坐着。没对哲学家之间都由一个叉子(因此，一共有5个)。每个哲学家在思考的时候都会花费一定时间，在这段时间内他们不会使用叉子直到它们开始进餐。为了进餐，一个哲学家需要两个叉子，都是左边一个右边一个。为了竞争叉子，就导致了同步问题的发生，从而让这个问题变成了并发编程问题。

![figure31_14.png "哲学家进餐"](#figure31_14.png "哲学家进餐")

这里每个哲学家有一个基本循环，假设每个都由一个唯一线程标识符`p`(从0到4):
```c
while (1)
{
    think();
    get_forks(p);
    eat();
    put_forks(p);
}
```
关键的挑战是，编写没有死锁，没有哲学家饥饿或者从来不进餐以及并发度高(例如，在同一时刻尽可能多的哲学家进餐)的`get_forks()`和`put_forks()`例程。根据Downey的解决办法，我们要使用少量帮助函数找到解决办法。他们是：
```c
int left(int p) { return p; }
int right(int p) { return (p + 1) % 5; }
```
当一个哲学家`p`想要获取他左边的叉子，他就调用`left(p)`。类似的，哲学家`p`获取右边的叉子就调用`right(p)`内部处理了当最后一个哲学家(`p=4`)试图获取自己右边的叉子时获取的叉子是0号叉子。

我们还需要一些信号量来解决这个问题。让我们假设需要5个，每个叉子有一个：`sem_t forks[5]`。

#### 无效的方案
我们尝试第一种解决方法。假设我们初始化了每个信号量(`fork`数组内)的值为1。同样假设每个哲学家知道自己的编号(p)。那么我们可以编写`get_forks()`和`put_forks()`例程(代码片段31_15)。
```c
void get_forks(int p)
{
    sem_wait(&forks[left(p)]);
    sem_wait(&forks[right(p)]);
}

void put_forks(int p)
{
    sem_post(&forks[left(p)]);
    sem_post(&forks[right(p)]);
}
```
__代码片段31_15：`get_forks()`和`put_forks()`例程__

这个错误的解决办法直觉如下。为了获取叉子，我们就去每个叉子的锁：先取左边叉子的锁，然后取右边叉子的锁。当我们完成进餐，我们就释放它们。不幸的是，在这个例子里面，简单意味着错误。

问题就是 __死锁__。如果每个哲学家碰巧都是先取自己左边的叉子后取右边的叉子，每个哲学家就会永远阻塞在持有一个叉子并等待另一个叉子。具体的说，哲学家0抓住了叉子0，哲学家1抓住了叉子1，哲学家2抓住了叉子2，哲学家3抓住了叉子3，哲学家4抓住了叉子4；所有叉子都被请求了，因此所有的哲学家都阻塞在等待另一个哲学家正在处理的叉子。我们很快就会详细学习死锁；现在，可以很安全的说这不是一个可以工作的方案。

####一个解决方案：打破依赖
解决这个问题最简单的办法是修改至少一个哲学家获取叉子的方式；事实上，这就是Dijkstra解决这个问题的方法。具体来说，让我们假设哲学家4(数字最高的那位)是和其他哲学家获取叉子的方式不同的人(代码片段31_16)；`put_forks()`保持不变。
```c
void get_forks(int p)
{
    if (p == 4)
    {
        sem_wait(&forks[right(p)]);
        sem_wait(&forks[left(p)]);
    }
    else
    {
        sem_wait(&forks[left(p)]);
        sem_wait(&forks[right(p)]);
    }
}
```
__代码片段31_16:在`get_forks()`里面打破依赖__

因为最后一个哲学家试图先取右边后取左边的叉子，就不会有所有哲学家抓取了一个叉子然后阻塞在等待另一个叉子，循环等待被打破了。思考这个解决方案的结果(ramifications)，说服自己这个可以工作。

其它类似这个"著名"问题的有 __吸烟者问题__ 和 __睡着的理发师问题__。如果有兴趣可以去了解一下。

###31.7 线程节流(Thread Throttling)
另一个简单的使用信号量的例子偶尔出现，我们在这里描述一下。具体的问题是这样：程序员如何阻止过多的线程在某一时刻都执行从而让系统陷入困境？答案：确定"过多"的阈值，然后使用信号量来限制并发执行任务代码的线程数量。我们成这个方式叫做 __节流(throttling)__，它被看作 __许可控制(admission control)__ 的一个形式。

让我们考虑一个更具体的例子。想象一创建了数百个线程并行的处理一些问题。然而，在代码的某些部分，每个线程会请求一大块内存去执行部分计算逻辑；让我们称这段代码叫做 _内存敏感区(memory-intensive region)_。如果所有的线程在同一时刻都进入了内存敏感区，请求分配的内存总和会超过机器上物理内存大小。结果就是，机器会开始抖动(thrashing)(例如，从磁盘上换入换出页)，然后整个计算将会慢到爬行。

###31.8 如何实现信号量
最后，让我们使用我们的底层同步原语，锁和条件变量，实现我们自己版本的信号量--__Zemaphores__。这个任务很直接，代码31_17显示了结果。
```c
typedef struct __Zem_t
{
    int value;
    pthread_cond_t cond;
    pthread_mutex_t lock;
} Zem_t;

// only one thread can call this
void Zem_init(Zem_t *s, int value)
{
    s->value = value;
    Cond_init(&s->cond);
    Mutex_init(&s->lock);
}

void Zem_wait(Zem_t *s)
{
    Mutex_lock(&s->lock);
    while (s->value <= 0)
        Cond_wait(&s->cond, &s->lock);
    s->value--;
    Mutex_unlock(&s->lock);
}

void Zem_post(Zem_t *s)
{
    Mutex_lock(&s->lock);
    s->value++;
    Cond_signal(&s->cond);
    Mutex_unlock(&s->lock);
}
```
__代码片段31_17:使用锁和条件变量实现Zemaphores__

上面的代码，我们只用了一个锁和一个条件变量，然后用了一个状态变量跟踪信号量的值。认真学习这个代码并搞懂它。

我们的Zemaphore和Dijkstra定义的纯信号量有一个细微差别，就是我们不维护这个恒等关系：当信号量的值为负数时，等于等待的线程数；事实上，我们的Zemaphores值永远不会比0小。这个行为更容易实现并且和当前Linux的实现一致。

奇怪的是，从信号量来构建条件变量是一个很诡异的命题。某些高水平并发程序员试图在Windows环境实现这个，bug接踵而至。你可以自己尝试一下，看看你能够找到为什么使用信号量构建条件变量比它看起来的要更具挑战性。
>####tip:仔细对待一般化
>一般化的抽象技术在系统设计上非常有用，在这里一个好的想法可以轻微的扩展从而解决更大类的问题。然而，当一般化时要当心；就想Lampson警告我们"不要泛化；泛化通常是错的"。
>
>我们可以把信号量看作是锁和条件变量的一般版本；然而，这种泛化是必须的么?同时，由于使用信号量实现条件变量的困难性，可能这种泛化并不如你想象的那么一般化。
###31.9 总结
信号量是一个强大灵活的编写并发程序的原语。有些程序员因为它们的简洁性和实用性只使用它们而不使用条件变量和锁。

在本章，我们已经呈现了几个经典问题和对应的解决方案。如果你有兴趣找到更多，有很多材料供你参考。其中一个伟大(且免费的材料)是Allen Doweny编写的一本使用信号量编写并发程序的书。这本书有很多问题你可以探究，用来提升你对信号量和并发的理解。成为一个真正的并发专家需要多年时间，超越你在这节课五一是掌握并发的关键一步。

[<sub id="1">content1</sub>](#content1) 历史上，Dijkstra称`sem_wait()`为`P()`称`sem_post()`为`V()`。这些简写来自于荷兰语；有趣的是，据传是他们继承的荷兰词汇随着时间在改变。最开始`P()`来自'passering'(传给)，`V()`来自'vrijgave'(释放)；后来，Dijkstra写的`P()`来自"prolaag",是"probeer"(尝试)和"verlaag"(减一)的组合词，`V()`来自"verhoog"，这个词意味着"加一"。有时候，人们也叫他们上下。使用荷兰版本取震惊你的朋友，或者迷惑它们。
[<sub id="2"></sub>](#content2) 事实上，根据模块化目的把对`mutex`的请求/释放放到`put()`和`get()`函数更加自然。