## 分页：更快速的转换(TLBs)
使用分页作为支撑虚拟内存的核心机制可能会导致高性能负载。通过把地址空间分割为固定尺寸的小单元(例如，页)，分页要求大量的映射消息。由于映射信息通常存放在物理内存中，分页逻辑上要求对每个由程序生成的虚拟地址空间多一个额外的内存查找。在每一次指令取或者显式加载或存储前都要到内存中查找转换信息会变得非常慢，所以我们的问题是：
>### 症结：如何加速地址转换
>我们要如何加速地址转换，并避免似乎是分页要求的额外内存引用？需要硬件的什么支持？需要OS做什么？

当我们想要事情变快，OS常需要来自OS老朋友：硬件的帮助。为了加速地址转换，我们将要增加一个 __translation-lookaside buffer或者TLB__，他是CPU __内存管理单元 memory-management unit(MMU)__ 的一部分，它是硬件为了缓存经常使用的 虚拟到物理地址转换：可能，更好的名字应该是 __地址转换缓存 address-translation cache__。根据每次虚拟地址引用，硬件首先检查TLB是否缓存了想要的转换信息；如果是，转换就不需要查找页表(它包含了所有转换信息)就可以快速的执行。由于它们巨大的性能提升，TLBs让虚拟内存变得可能。

### 19.1 TLB 基本算法
下面代码显示了硬件是如何控制虚拟地址转换的大概模式，假设一个简单的 __线性页表linear page table__ (例如，页表是一个数组)和一个 __硬件管理的TLB hardware-managed TLB__ (例如，硬件负责大多数页表访问的职责；我们将在下面做更详细的介绍)。

```python
 VPN = (VirtualAddress & VPN_MASK) >> SHIFT
 (Success, TlbEntry) = TLB_Lookup(VPN)
 if (Success == True) // TLB Hit
    if (CanAccess(TlbEntry.ProtectBits) == True)
        Offset = VirtualAddress & OFFSET_MASK
        PhysAddr = (TlbEntry.PFN << SHIFT) | Offset
        Register = AccessMemory(PhysAddr)
    else
        RaiseException(PROTECTION_FAULT)
 else // TLB Miss
    PTEAddr = PTBR + (VPN * sizeof(PTE))
    PTE = AccessMemory(PTEAddr)
    if (PTE.Valid == False)
        RaiseException(SEGMENTATION_FAULT)
    else if (CanAccess(PTE.ProtectBits) == False)
        RaiseException(PROTECTION_FAULT)
    else
        TLB_Insert(VPN, PTE.PFN, PTE.ProtectBits)
        RetryInstruction()
```
硬件按照算法工作是这样子的：首先，从虚拟地址(代码中的行1)提取虚拟页号(VPN)，然后检查TLB是否存放了这个VPN的转换信息(行2)。如果有，我们就有了一个 __TLB命中 TLB hit__，这意味着TLB存放了这个转换信息。成功！我们现在可以从相应的TLB条目提取页帧号(PFN)，把它和在原始虚拟地址中的偏移连接起来，组成想要的物理地址(physical address PA)，然后，访问内存(行5-7)，如果保护位检查没有失败(行4)。

如果CPU没有在TLB中找到转换信息(一个 __TLB miss__),我们要再做更多事情。在这个例子里，硬件通过访问页表查找转换信息(行11-12)，然后，如果进程生成的虚拟地址引用是有效且可访问(行13，15)，用这个地址转换更新TLB(行18)。这些操作消耗很高，主要是由于额外内存引用需要访问页表(行12)。最后，一旦TLB被更新了，硬件重试这个指令，这一次，转换信息在TLB中，然后内存引用就处理的很快。

TLB，想很多缓存一样，是构建在，通常，转换会在缓存中发现(会命中)的这一假设。如果是，只需要增加很小的负载，因为TLB是在靠近处理核心被发现的，然后被设计的运行很快。如果未命中，高花费的分页就会发生；必须访问页表来找到转换信息，然后一个额外内存引用(或者更多，如果有跟复杂的页表)结果。如果这个常常发生，程序会显著的运行很慢；门窗访问，相应的更多的CPU指令，花费也很高，然后TLB miss会导致更多的内存访问。因此，我们希望尽可能避免TLB miss。

### 19.2 例子：访问一个数组
为了清晰的显示TLB的运作，让我们看一个简单的虚拟地址跟踪，看看TLB是如何可以提高性能。在这个例子中，让我们假设我们在内存中有一个数组，由10个4字节整数组成，从虚拟地址100开始。进一步假设我们有一个很小的8bit虚拟地址空间，包含了16字节页；因此，一个虚拟地址被分成4bit的VPN(一共16个虚拟页)和一个4bit的偏移量(那些页每个都是16字节)。

![图19_2 "例子：在很小地址空间的数组"](Figure19_2.png "例子：在很小地址空间的数组")

图19_2显示了数组在系统中16个16字节页的布局。正如你看到的，数据开始的条目(`a[0]`)开始在(VPN=06,offset=04)；只有3个4字节整数在页中。数组延续到下一个页(VPN=07),包含了后4个条目(`a[3]`...`a[6]`)。最后，剩下的3个条目(`a[7]`...`a[9]`)位于地址空间接下来的页上(VPN=08)。

现在，让我们考虑一个简单的循环，循环会访问数组每一个元素，在C中显示如下：
```C
int sum = 0;
for (i = 0; i < 10; i++) {
    sum += a[i];
}
```
为了简化问题，我们将只在意循环生成的对于数组的内存访问(忽略变量`i`和`sum`，以及他们的指令)。当一个数组元素(`a[0]`)被访问，CPU将看到一个到虚拟地址`100`的加载。硬件从(VPN=06)提取VPN，然后使用它检查TLB是否是一个有效的转换。假设这个程序第一次访问这个数组，结果就是TLB miss。

下一个访问`a[1]`，这里就有好消息了：TLB命中！由于数组第二个元素放置在第一个元素的下一位，他跟第一个元素存在于同一个页；当访问数组第一个元素的时候，由于我们已经访问了这个页表，转换信息已经加载到了TLB中。这就是我们成功的原因。访问`a[2]`会遇到类似的成功(另一个命中)，因为它和`a[0]`，`a[1]`一样，再用一个页中。

不幸的是，当程序访问到`a[3]`,我们遇到了另一个TLB未命中。然而，再一次，接下来的条目(`a[4]`...`a[6]`)将会命中TLB，因为它们都在内存中的同一个页。

最后，访问`a[7]`会导致最后一次TLB未命中。硬件为了虚拟页在物理内存中的位置再一次查找页表，然后相应的，更新TLB。最后两个访问(`a[8]`...`a[9]`)享受到了这次的TLB更新带来的好处；当硬件为了找到它们的转换信息查找TLB，会有两次命中。

让我们总结一下在十次数组访问中TLB的行为；未命中，命中，命中，未命中，命中，命中，命中，未命中，命中，命中。因此，我们TLB的 __命中率 hit rate__，也就是命中的次数除以总共的访问次数，是70%。尽管这看起来不是很高(事实上，我们希望命中率接近100%)，但它不是0，这很令人惊讶。尽管这是程序第一次范文数组，TLB因为 __空间局部性 spatial locality__ 提升了性能。数组的元素被打包到页中(例如，它们互相之间在空间上很接近)，因此只有第一次访问页上一个元素才会导致(yield)一次TLB未命中。

同样记住在这个例子中页大小的作用。只要页大小打两倍(32字节，而不是16)，数组访问的未命名将会更少。一个典型的页大小一般是4KB，像这样的类型，基于数组的访问会有显著的TLB性能提升，在每个页访问只会遇到一次未命中。

TLB性能最后一个点是：如果程序，再循环结束后很快再次访问数组，我们将会遇到更好的结果，假设我们有足够大的TLB缓存：命中，命中，命中，命中，命中，命中，命中，命中，命中，命中。在这个例子中，TLB命中率这么高的原因是因为 __时间局部性 temporal locality__，例如，及时地快速重新引用内存元素。就像任何缓存一样，TLB的成功依赖于程序的时间和空间局部性属性。如果感兴趣的程序展示了(exhibit)这种局部性(而且很多程序也是这样)，TLB命中率就会变得非常高。

>### 提示：只要可能就用缓存
>在计算机系统中缓存是最基础的性能提升技术之一，它一次又一次让常见问题变快。硬件缓存背后的想法是利用指令和数据引用的局部性。通常有两种局部性：__时间局部性__ 和 __空间局部性__。时间局部性，背后的想法是：在后面会很快再次访问数据。想一下循环变量或者循环内的指令；随着时间它们被重复访问。空间局部性：他的想法是：如果一个程序访问了地址`x`的内存，它很快会访问`x`附近的内存。想象一下依次访问数组的元素情况，当然这些属性依赖程序具体的性质，这不是必须准守的(hard-and-fast)法律，它更像经验规律
>硬件缓存，无论是为了指令，数据，或者地址转换(就像我们的TLB)通过保存内存的副本到小的快速的片上内存从而利用了局部性。不用去在(缓慢的)内存中满足请求，如果有缓存中有一个副本在处理器附近，处理器可以快速的检查，如果它可以工作，处理器可以快速访问它(例如，更少的CPU周期)并且避免了CPU访问内存产生昂贵的时间(很多纳秒)。
>你可能会担心：如果缓存(像TLB)这么好用，为什么我们不生产更大的缓存并把数据都存到里面？不幸的是，这里我们遇到了更基本的物理定律。如果你想要快速的缓存，他就必须很小，类似光速和其他物理约束变得相关起来。任何大的缓存都会很慢，这就违背了目的。因此，我们就只有小而快速的缓存，剩下的问题就是如何最好的利用它们以提升性能

### 19.3 谁来处理TLB未命中？