## 分页：更快速的转换(TLBs)
使用分页作为支撑虚拟内存的核心机制可能会导致高性能负载。通过把地址空间分割为固定尺寸的小单元(例如，页)，分页要求大量的映射消息。由于映射信息通常存放在物理内存中，分页逻辑上要求对每个由程序生成的虚拟地址空间多一个额外的内存查找。在每一次指令取或者显式加载或存储前都要到内存中查找转换信息会变得非常慢，所以我们的问题是：
>### 症结：如何加速地址转换
>我们要如何加速地址转换，并避免似乎是分页要求的额外内存引用？需要硬件的什么支持？需要OS做什么？

当我们想要事情变快，OS常需要来自OS老朋友：硬件的帮助。为了加速地址转换，我们将要增加一个 __translation-lookaside buffer或者TLB__，他是CPU __内存管理单元 memory-management unit(MMU)__ 的一部分，它是硬件为了缓存经常使用的 虚拟到物理地址转换：可能，更好的名字应该是 __地址转换缓存 address-translation cache__。根据每次虚拟地址引用，硬件首先检查TLB是否缓存了想要的转换信息；如果是，转换就不需要查找页表(它包含了所有转换信息)就可以快速的执行。由于它们巨大的性能提升，TLBs让虚拟内存变得可能。

### 19.1 TLB 基本算法
下面代码显示了硬件是如何控制虚拟地址转换的大概模式，假设一个简单的 __线性页表linear page table__ (例如，页表是一个数组)和一个 __硬件管理的TLB hardware-managed TLB__ (例如，硬件负责大多数页表访问的职责；我们将在下面做更详细的介绍)。

```python
 VPN = (VirtualAddress & VPN_MASK) >> SHIFT
 (Success, TlbEntry) = TLB_Lookup(VPN)
 if (Success == True) // TLB Hit
    if (CanAccess(TlbEntry.ProtectBits) == True)
        Offset = VirtualAddress & OFFSET_MASK
        PhysAddr = (TlbEntry.PFN << SHIFT) | Offset
        Register = AccessMemory(PhysAddr)
    else
        RaiseException(PROTECTION_FAULT)
 else // TLB Miss
    PTEAddr = PTBR + (VPN * sizeof(PTE))
    PTE = AccessMemory(PTEAddr)
    if (PTE.Valid == False)
        RaiseException(SEGMENTATION_FAULT)
    else if (CanAccess(PTE.ProtectBits) == False)
        RaiseException(PROTECTION_FAULT)
    else
        TLB_Insert(VPN, PTE.PFN, PTE.ProtectBits)
        RetryInstruction()
```
硬件按照算法工作是这样子的：首先，从虚拟地址(代码中的行1)提取虚拟页号(VPN)，然后检查TLB是否存放了这个VPN的转换信息(行2)。如果有，我们就有了一个 __TLB命中 TLB hit__，这意味着TLB存放了这个转换信息。成功！我们现在可以从相应的TLB条目提取页帧号(PFN)，把它和在原始虚拟地址中的偏移连接起来，组成想要的物理地址(physical address PA)，然后，访问内存(行5-7)，如果保护位检查没有失败(行4)。

如果CPU没有在TLB中找到转换信息(一个 __TLB miss__),我们要再做更多事情。在这个例子里，硬件通过访问页表查找转换信息(行11-12)，然后，如果进程生成的虚拟地址引用是有效且可访问(行13，15)，用这个地址转换更新TLB(行18)。这些操作消耗很高，主要是由于额外内存引用需要访问页表(行12)。最后，一旦TLB被更新了，硬件重试这个指令，这一次，转换信息在TLB中，然后内存引用就处理的很快。

TLB，想很多缓存一样，是构建在，通常，转换会在缓存中发现(会命中)的这一假设。如果是，只需要增加很小的负载，因为TLB是在靠近处理核心被发现的，然后被设计的运行很快。如果未命中，高花费的分页就会发生；必须访问页表来找到转换信息，然后一个额外内存引用(或者更多，如果有跟复杂的页表)结果。如果这个常常发生，程序会显著的运行很慢；门窗访问，相应的更多的CPU指令，花费也很高，然后TLB miss会导致更多的内存访问。因此，我们希望尽可能避免TLB miss。

### 19.2 例子：访问一个数组
为了清晰的显示TLB的运作，让我们看一个简单的虚拟地址跟踪，看看TLB是如何可以提高性能。在这个例子中，让我们假设我们在内存中有一个数组，由10个4字节整数组成，从虚拟地址100开始。进一步假设我们有一个很小的8bit虚拟地址空间，包含了16字节页；因此，一个虚拟地址被分成4bit的VPN(一共16个虚拟页)和一个4bit的偏移量(那些页每个都是16字节)。

![图19_2 "例子：在很小地址空间的数组"](Figure19_2.png "例子：在很小地址空间的数组")

图19_2显示了数组在系统中16个16字节页的布局。正如你看到的，数据开始的条目(`a[0]`)开始在(VPN=06,offset=04)；只有3个4字节整数在页中。数组延续到下一个页(VPN=07),包含了后4个条目(`a[3]`...`a[6]`)。最后，剩下的3个条目(`a[7]`...`a[9]`)位于地址空间接下来的页上(VPN=08)。

现在，让我们考虑一个简单的循环，循环会访问数组每一个元素，在C中显示如下：
```C
int sum = 0;
for (i = 0; i < 10; i++) {
    sum += a[i];
}
```
为了简化问题，我们将只在意循环生成的对于数组的内存访问(忽略变量`i`和`sum`，以及他们的指令)。当一个数组元素(`a[0]`)被访问，CPU将看到一个到虚拟地址`100`的加载。硬件从(VPN=06)提取VPN，然后使用它检查TLB是否是一个有效的转换。假设这个程序第一次访问这个数组，结果就是TLB miss。

下一个访问`a[1]`，这里就有好消息了：TLB命中！由于数组第二个元素放置在第一个元素的下一位，他跟第一个元素存在于同一个页；当访问数组第一个元素的时候，由于我们已经访问了这个页表，转换信息已经加载到了TLB中。这就是我们成功的原因。访问`a[2]`会遇到类似的成功(另一个命中)，因为它和`a[0]`，`a[1]`一样，再用一个页中。
