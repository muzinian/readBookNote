## 调度(scheduling):介绍
现在,OS运行进程的底层机制(例如,上下文切换)对我们来说应该是很清楚了,如果你还不清楚,回到一两章之前,重新在读一遍那些关于事情是如何工作的描述。然而,我们必须要了解OS调度器工作方式这一高层协议。我们将要做的是:呈现一系列的**调度协议(scheduling policies)** (有时也叫**disciplines**(注:不知道改翻译成什么。。)),这些协议是各种聪明且努力的人经过多年的研发成果。

事实上,调度的起源早于计算机系统,应用到计算机的早期方法来自于运营管理领域。不必惊讶于这一事实:装配线以及其他很多人类劳动也需要调度,在那里面也存在许多同样的关心的事,包括对效率的极度渴求。这里,我们的问题就是:
>#### 症结:如何开发调度策略
>我们应该如何开发一个为了考虑调度策略的基础框架?关键的假设是什么?什么样的测量标准是重要的?最早期的计算机系统中用到了什么样的基本方法?

###7.1 工作量假设
在涉及到各种可能的策略之前,让我们先对运行在系统之上的进程先做一些简单的假设,这些有时候也笼统的称为工作量。构建一个协议的关键部分是决定工作量,对工作量了解的越多,你就也能够对策略进行调优。

我们现在对于工作量所做出的假设很不现实,但是目前来说还好,因为随着我们继续下去我们将会放开这些假设,最终,我们将要开发一个全功能的调度策略。

我们将对运行在系统的进程(有时也叫做**jobs**)做下列假设:
1. 每个job运行时间都相同;
2. 所有的job都在同一时刻到达;
3. 一旦开始,每个任务都会一直运行到完成;
4. 所有的job只使用CPU(例如,它们不会进行I/O操作);
5. 每个job的运行时间是已知的。

我们上面说过,这些假设都是不现实的,但是就想在Orwell的《动物农场》里面说的,有些动物比其他动物更加平等,在本章中,有些假设比其他假设更加不现实。进一步说,job的运行时间已知这一假设可能会让你感到困扰,这一假设会使得调度器无所不知,尽管这(可能)很好,但是这似乎并不会发生。

### 7.2 调度度量标准(scheduling metrices)
除了对工作量做出假设,我们还需要一个东西来确保我们可以比较不动的调度策略:**调度测量标准(scheduling metric)**。我们使用标准(metric)来测量东西,在调度中有不同的标准都有意义。

现在,为了简化问题,我们就只列出一个标准:**执行时间(turnaround time)**(turnaround:往返时间,这里的意思就是完成job所用的时间)。job的执行时间被定义为job完成时间减去job到达系统的时间。更形式化的:
>T<sub>_turnaround_</sub> = T<sub>_completion_</sub> − T<sub>_arrival_</sub>&nbsp;&nbsp;&nbsp;(7.1)

因为我们假设了所有的job都在同一时刻到达,因此 T<sub>_arrival_</sub>=0 而 T<sub>_turnaround_</sub> = T<sub>_completion_</sub>。这一事实将在我们放宽了前述的假设之后改变。

你可能注意到执行时间是一个完美的测量标准,这将是我们本章的主要关注点。另一个有意思的标准是公平性(fairness),通过 **Jain's Fairness Index**测量。在调度中,性能和公平性常常是对立的:举个例子,一个调度器可能通过阻止几个job运行为代价来优化性能,这就降低了公平性。这一难题向我们展示了生活并不总是完美的。

### 7.3 先入先出(First In,First Out,FIFO)
我们可以实现的最基本的调度算法被叫做先入先出调度算法,有时也叫先来先服务算法(First Come,First Served FCFS)。FIFO有很多优秀的属性:他显然很简单也就是很容易实现。再者,按照我们的假设来的话,它工作的很好。

让我们一起做一个快速的例子。想象有三个jobs(A,B和C)大致在同一时刻(T<sub>_arrival_</sub>=0)到达了系统。因为FIFO必须要把一些job放在首位,让我们假设尽管它们是同时到达的,A略微早于B到达,B略微早于C到达。同时假设每个job运行10秒钟。对于这些jobs,平均执行时间(average turnaround time)是多长?

![Figure7.1:FIFO简单的例子](Figure7_1.png "FIFO简单的例子")

从图7.1来看,你可以看到A在10处结束,B在20,C在30。因此,这三个任务的平均执行时间就是(10+20+30)/3=20。计算执行时间就是这么简单。

现在,让我们放宽一个假设。特别的,让我们放宽假设1,也即是不在假设每个任务都运行同样的时间。现在FIFO是如何运行的呢?你能构造什么样的工作量让FIFO运行的比较差?

相比你已经想出来了,但是以防万一,让我们举一个例子,他阐释了有着不同运行时间的jobs是如何导致FIFO调度变糟糕的。特别的,让我们假设有三个jobs(A,B和C),这一次A运行100秒,B,C运行10秒。

![Figure7.2:为何FIFO不在好用了](Figure7_2.png "为何FIFO不在好用了")

从图7.2中可以看到,A在开始的100秒内占据了全部的运行时间,B和C没有任何机会运行。因此,这个系统的平均执行时间很高:(100+110+120)/3=110,痛苦的110秒。

这个问题大体上涉及到**convoy effect(车队效应)**,一些相对较短的潜在资源消费者被排在了重量级资源消费者后面。这个调度场景可能提醒你想起在只有一个结账窗口的食品商店前,你的前面有着一个拿着装满三个购物车和一个检查单的人时你的感觉,这将要花费很长时间。

我们应该怎么做?我们如何能够开发出一个更好的算法来处理有着不同运行时间这个新的现实中的jobs?先想一想,然后继续阅读?

### 7.4 最短任务最先(Shortest Job First SJF)
事实证明,有一个简单方法可以解决这个问题:事实上这个主意来自于运营研究领域并应用于计算机系统的job调度。新的调度策略激就是**最短任务最先(Shortest Job First SJF)**,这个名字很好记忆,它完整的描述了这个策略:先运行最短的job,然后是次短的等等。

![Figure7.3:SJF 简单的例子](Figure7_3.png "SJF 简单的例子")

让我们对上一个例子使用SJF策略看看。图7.3显示了运行结果。希望这个图能够清楚显示出为什么SJF对于平均执行时间有这更好的表现。通过简单的在A之前运行B和C,SJF把平均时间从110减少到了50((10+20+120)/3=50),套高了一倍多。
>tip:SJF原则
>最短任务最先显示了一个通用的调度原则,他可以应用到任何对于 每消费者可感知执行时间(the perceived turnaround time per customer) 很重要的系统。想象你曾拍过的任意一个队:如果问题中的商家关心消费者的满意度,它们就可能考虑到(into account)采用SJF策略。举个例子,食品商店通常会有一个 “小于10个物品” 队伍来确保那些只有少量货物的购物者不会被那些为了抵御即将到来的核冬天而采购的家庭耽误付款。

事实上,根据我们关于所有job都在同一时刻到达的假设,我们可以证明SJF是一个最优调度算法。我们现在有了SJF这一个很好的调度策略,但是我们的假设依旧很不现实。让我们在放宽另一个。特别的,我们的目标是假设2,现在我们可以假设任务不是一次性到达,而是可以在任何时候都到达。现在会导致什么问题?

这里,我们可以用再次用一个例子阐述这个问题。这一次,假设A在 _t_ = 0 时到达,运行时间需要100秒,B和C在_t_=10 时到达,每个的运行时间是10秒。根据单纯的SJF,我们得到的调度如图:

![Figure7.4:SJF B和C延迟到达](Figure7_4.png "SJF B和C延迟到达")

你可以从图中看到,即使B和C只是比A晚到一会儿,它们仍然被迫要等待带A完成,这就导致了同样的convoy effect问题。这三个任务的平均完成时间是103.33秒(100+(110-10)+(120-10))/3=103.33。调度器此时应该如何做?

### 7.5 耗时最短任务优先(Shortest Time-to-Completion First STCF)
为了解决这个问题,我们需要放宽假设3(任务必须要一直运行到完成),让我们开始这样做。我们需要调度器自己内部有一些机制(machinery)。你可能猜到了,根据我们之前关于定时器中断和上下文切换的讨论,调度器当然可以在B和C到达时做一些操作:他可以**抢占(preempt)** 任务A然后决定运行其他任务,可能是稍后继续运行A。根据我们的定义,SJF是一个**非抢占式(non-preemptive)** 调度器,这就导致了上面描述的问题。

幸运的是,有一种调度器可以给SJF增加抢占功能,就是所谓的**耗时最短任务优先(Shortest Time-to-Completion First STCF)** 或者**抢占式最短任务优先(Preemptive Shortest Job Firest PSJF)** 调度器。无论何时,一个任务进入到系统,STCF调度器决定剩余的任务中(包括这个新到的任务)有最少的剩余时间(意思是执行时间最少),然后调度这个任务执行。在我们的例子里,STCF会抢占A然后运行B和C直到完成;只有它们结束A才会重新被调度。下图显示这个例子:

![Figure7.5:STCF 简单的例子](Figure7_5.png "SJF 简单的例子")

这个结果就是大大节省了平均执行时间:50秒(((120-0)+(20-10)+(30-10))/3)。像之前一样,按照我们的假设的话,STCF也可以证明是最优的;根据如果所有任务同时到达则SJF是最优的这一结果,你应该能够看到STCF是最优这一结论背后的直觉。

### 7.6 新的度量标准:响应时间

如果我们知道任务长度、任务只使用CPU并且我们唯一的测量标准是执行时间,STCF应该是一个伟大的策略。事实上,对于一些早期的批处理计算系统,这种类型的调度算法很合理。然而,时分机器的引入改变这些。现在,用户可以坐在终端前,也希望这来自系统的交互性能。因此,一个新的度量标准产生了:响应时间。

响应时间的定义是:任务到达系统到第一次被调度运行的耗时。更形式化的:
>T<sub>_response_</sub> = T<sub>_firstrun_</sub> − T<sub>_arrival_</sub>&nbsp;&nbsp;&nbsp;(7.2)

举个例子,如果我们有上面提到的调度器(并且任务A在0时到达,B和C在10时到达),每个任务的响应时间如下:任务A是0,任务B是0,任务C是10(平均是3.33)。

你可能会想,STCF以及相关的策略对于响应时间不是特别的好。如果三个任务在同时到达,举个例子,第三个任务必须等待前两个任务运行完它们的全部(run _in their entirety_)才会得到一次调度。这个任务对于执行时间有很好的表现,但是在响应时间和交互方面表现得很差。确实,想象下你坐在终端前,打字,必须要等待10秒才能看到来自系统的响应,这只是因为在你的任务前有其他任务得到了调度,这太不安逸了。

这里,我们就有了另一个问题:我们如何构建一个对响应时间敏感的调度器?

### 7.7 轮询
为了解决这个问题,我们将介绍一个新的调度算法,经典的**轮询(Round-Robin RR)** 调度。基本想法很简单:代替了任务一旦运行必须要完成,RR运行一个任务一个 **时间片(time slice)** (有时也叫 **调度量子(scheduling quantum)**)的时间然后切换到任务队列中的其它任务。他重复这个过程知道任务完成。由于这个原因,RR有时也叫做**时间片(time-slicing)**。记住,时间片的长度必须是定时器中断周期的整数倍:也既,如果定时器中断的周期是10毫秒,时间片可以是10,20或者其它10ms的整数倍。

为了更详细的理解RR,让我们看一个例子。假设有三个任务A,B和C同时到达系统,每个希望运行5秒。SJF调度器在运行其它任务前要等待当前任务运行完成(图7.6)。相反,有着一个1秒的时间片的RR会快速地在这些任务中切换(cycle through the jobs quickly)(图7.7)。

![Figure7.6,Figure7.7:SJF和Round Robin对于响应时间的对比](Figure7_6&7.png "SJF和Round Robin对于响应时间的对比")

RR的平均响应时间是:(1+2+3)/3=1;而SJF则是(0+5+10)3=5。

你可以看到,对于RR来说,时间片是关键。时间片越短,RR的响应时间度量就会有更好的性能。然而,让时间片太短也有问题:突然间,上下文切换的花费回主宰所有的性能。因此,对于时间片长度的决定显示了系统设计者的取舍,设置足够长的时间片以摊销上下文切换所带来的花销,但是不设置太长的时间以至于系统无法再响应。
>tip:摊销可以减少花费
>**摊销(amortization)** 这一通用技术常常用于那些有着固定消耗操作的系统中。通过比平常更少的产生这种花费(即,少执行几次这种操作),系统总成本就会减少。举个例子,如果时间片被设置为10ms,上下文切换花费1ms,大约有10%的时间被用来执行上下文切换而浪费了。如果我们想要分摊这种花销,我们可以增加时间片,例如,增加到100ms。在这种例子下,少于1%的时间被用于上下文切换,所以时间分片调度(time-slicing)的花销被分摊了。

记住,上下文切换的花销不单单是由OS保存和恢复几个寄存器的操作产生的。当程序运行时,它们在CPU缓存,TLBs,分支预测器和其它片上(on-chip)硬件中构建了大量的状态。切换到其它job会导致这些状态被冲刷掉(flushed),跟当前新运行的job相关的状态被引入,这些就会导致可观察的性能花销。

RR,加上合理的时间片,对于只考虑响应时间这一个度量标准来说,是一个非常好的调度器。但是如果考虑到执行时间呢?然我们再一次看看上面的例子。A,B和C,每个任务运行时间是5秒,同时到达系统,RR(有着1秒的时间片)作为调度器。从上面的图中可以看到,A在13秒结束,B在14秒,C在15秒,所以平均执行时间是14秒,相当的糟糕!

这不令人惊讶,如果执行时间是我们的度量标准的话,RR确实最糟糕的调度器之一。直观地,这应该很合理:RR所做的是尽他所能的拉长我们每个任务,但是,在转向下一个任务前,只运行每个job很短一段时间。由于执行时间只关注job何时完成,在某些情况下,RR几乎比简单的FIFO还要糟糕。

更一般的,任何策略(例如RR)是**公平的(fair)**,既,以一个小的时间片在各个活动的进程之间平分CPU,都将会在类似于执行时间的度量上面表现糟糕。确实,这是一个固有的取舍:如果你要不公平,你可以运行短的任务知道完成,但是会导致响应时间慢;如果你关心公平性,响应时间下降了,但是执行时间变长了。这种类型的取舍在系统中很常见;毕竟鱼和熊掌不可兼得!

我们已经研究了两类调度器。第一类(SJF,STCF)优化了执行时间,但是对于响应时间很糟糕。第二类(RR)优化了响应时间,但是对于执行时间不理想。同时,我们仍然还有两类假设需要被放宽:假设4(jobs不执行I/O操作)和假设5(每个job的执行时间已知)。让我们继续解决它们。

### 7.8 与I/O结合
我们先放宽假设4--当然,所有的程序都执行I/O。想象一个程序不接受任何输入:每次他都会产生同样的输出。想象一个程序没有输出:有一句谚语:没人看见到在森林里的树;没有输出的任务不重要。

当一个job初始化一个I/O操作时,调度器显然需要做出相应的决定,因为当前运行的job将不会在I/O过程中使用CPU,它因等待I/O完成而被被**阻塞(blocked)**。如果I/O本送往硬盘驱动,进程可能要阻塞几毫秒或者更长,这依赖于当前驱动的负载。因此,此时调度器应该可能会调度其它job到CPU上。

当I/O完成时,调度器也需要做出相应的决定。当I/O完成发生了,就会引起一个中断,OS就会开始运行并把发起I/O的进程从阻塞状态切换回准备状态。当然,它当然可能甚至在那个时刻就决定运行这个job。OS应该如何对待各个job呢?

为了更好的理解这个问题,让我们假设有两个jobs,A和B,每个都需要50ms的CPU时间。然而,两者之间有一个显然的不同,A每运行10ms就会发起一个I/O请求(假设每次I/O花费10ms),于此相反,B就是简单的使用50ms的CPU而不发起I/O操作。调度器先运行A,然后运行B(图7.8)。

![Figure7.8:糟糕的资源使用](Figure7_8.png "糟糕的资源使用")

假设我们试图构建一个STCF调度器。这样一个调度器应该如何看待这个问题,既,A事实上是被拆分成了5个10ms的子任务而B就是单独的需要50ms的CPU时间呢?显然,仅仅是一个接一个的运行job而不把I/O花销考虑进来不合理。

一个常见的做法是把A的每个10ms子任务当作独立的job。也既,当系统开始时,他决定是执行10ms的A还是50ms的B。使用STCF,结果很显然,选择时间短的那个,在这个例子中,就是A。然后第一个A的子任务完成后,只剩下B,然后B就开始运行。然后A的一个新的子任务被提交了,然后它抢占了B然后运行了10ms。这样做需要允许**交替执行(overlap)**,当一个进程在等待I/O操作完成时另一个进程可以使用CPU,系统就可以更好的被利用(图7.9)。

![Figure7.9:交替运行允许对资源更好的利用](Figure7_9.png "交替运行允许对资源更好的利用")

>tips:交替运行确保了更好的利用率
>只要可能,交替运行各种操作来最大化系统的利用率。交替运行在多个领域都很有用,包括执行磁盘I/O或者向远程机器发送消息;在其它例子中,开始一个操作然后切换到其它工作是一个好的注意,它提升了系统整体的利用率和效率。

现在,我们看到了调度器如何与I/O协作的。通过把每一次的CPU间隙当作一个job,调度器确保那些"交互"进程可以频繁的运行。当那些交互job发起了I/O,CPU敏感的job运行,这就更好的利用了处理器。

### 7.9 没有更多的神谕了(Oracle,指的应该是知道job运行时间)
有了基本的方法来处理I/O,我们到达了我们最后的假设:调度器知道每个人物的执行时间。正如我们之前说过,这是我们做出的最糟糕的假设。事实上,在通用目的OS(也是我们关心的)里,OS通常对于job的执行时长知道的很少。因此,我们如果构建一个调度器有着类似于SJF/STCF的行为却没有这一先验的指示呢?更进一步,我们如何协调那些我们已经在RR调度器中了解到观点到我们新的方法里使得响应时间也很好的?
### 7.10 总结
我们介绍了调度策略背后的基本观念,也研究了两类方法。第一类运行系统剩下的job中最短的job因此对于执行时间有着很好的优化;第二个方法在全部的job中交替运行因此在响应时间上有很好的表现。两者都在对方的擅长中表现得很糟糕,这事系统中常见的固有取舍(trade-off)。我们也看到了我们如何和I/O协作,但是我们始终还没有解决OS不能看见未来这一本质上的无能(but have still not solved the problem of the fundamental inability of the OS to see into the future,不是很能准确的翻译这句话,感觉作者的意思是OS无法知道任务的执行时间,这从OS的本质上来说也无能为力)。简短的说,我们将看到,如何克服这个问题通过构建一个根据最近的过去来预测将来的调度器来克服这个问题。这个调度器就是所谓的**多级反馈队列(multi-level feedback queue)**,这是下一章的主题。
