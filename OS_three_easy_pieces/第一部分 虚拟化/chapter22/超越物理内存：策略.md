##超越物理内存：策略
在虚拟内存子系统内部，当你有很多空闲内存时生活很轻松。如果发生了页错误，你就在空闲页链表上面找到空闲页，把他赋给错误的页。不幸的是，如果只有很少的空闲内存事情就变得有趣了。在这种情况下，__内存压力(memory pressure)__ 迫使OS开始 __页出(paging out)__ 页为了给活跃使用的页腾出空间。决定哪个(或者哪些)页被 __剔除__ 是封装在OS的 __替换策略(replacement policy)__ 内；从历史来看，这是早期虚拟内存系统做出的最重要的决定之一，因为越老的系统物理内存越少。最低程度的，这个很有意思的策略集值得了解的更多些。这里是我们的问题：
>#### 症结:如何决定剔除那个页
>OS是怎么决定哪个(哪些)页从内存中剔除？这个决定是由系统的替换策略所决定的，这个策略通常遵循一些通用的原则(下面讨论的)但是也包括某些调整从而避免边界条件行为。
###22.1 缓存管理
在深入了解策略前，我们首先更详细的描述下我们试图解决的问题。给定一个存放了系统全部页子集的主存，他可以恰当的看做是系统内虚拟内存页的 __缓存(cache)__。因此，我们在为这个缓存挑选替换策略的目标是最小化 __缓存未命中(cache miss)__ 的数量，例如，为了最小化我们不得不从硬盘获取页的次数。换个角度，可以把我们的目标看做是最大化 __缓存命中(cache hit)__ 的数量，例如被访问页在内存中的次数。

再知道了缓存命中和缺失的数量后，我们就可以计算一个程序的 __平均内存访问时间(average memory access time AMAT)__(一个计算机架构师用来计算硬件缓存的度量标准)。具体来说，给定这些值，我们可以计算一个程序的AMAT：
$$AMAT = T_M + (P_{Miss}\cdot T_D)\quad\quad\quad\quad(22.1)$$
这里$T_M$表示访问内存的消耗，$T_D$表示访问磁盘的消耗，$P_{Miss}$表示的是没有在缓存中找到数据的(发生了缺失)概率。$P_{Miss}$值得变化范围从0.0到1.0，有时候我们倾向于使用百分比缺失率而不是概率值(例如10%的缺失率意味着$P_{Miss}=0.10$)。记住你总是要花费访问内存中数据的消耗；当你出现缺失，你就要额外增加从磁盘取数据的消耗。

例如，让我们想象一个机器，有一个(很小)地址空间，4KB大小，页大小是256字节。因此，虚拟地址包含两部分：一个4bit的VPN(最开始的几位)和8bit偏移量(剩下的几位)。因此，在这个例子里面，一个进程一共可以访问$2^4$或者16个页。在这个例子李，进程生成了如下的内存引用(例如，虚拟地址)：`0x000`,`0x100`,`0x200`,`0x300`,`0x400`,`0x500`,`0x600`,`0x700`,`0x800`和`0x900`。这些虚拟地址分别指向地址空间头十页每个的第一个字节(页编号是每个虚拟地址的第一个十六进制数字)。

让我们进一步假设除了虚拟页3每个页都已经在内存了。因此，我们的内存引用序列将会要如下行为：命中，命中，命中，缺失，命中，命中，命中，命中，命中，命中。我们可以计算 __命中率__(引用在内存找到的百分比)是:90%，因为10个引用中有9个在内存中。__缺失率__ 是10%($P_{Miss}=01$)。总的来说，$P_{Hit}+P_{Miss}=1.0$；命中率加缺失率的和是100%。

为了计算AMAT，我们需要知道访问内存和访问磁盘的耗费。假设访问内存的耗费($T_M$)大概10纳秒，访问磁盘的($T_D$)大概是10毫秒，我们就有了如下AMAT：$100ns+1ms$后者说是1.0001ms，大约1毫秒。如果命中率变成了99.9%($P_{miss}=0.001$)，结果就有点不同了:AMAT是10微妙，大概快100倍。随着命中率接近100%，AMAT接近100那纳秒。

不幸的是，正如你从这个例子中看到的，在现代系统中磁盘访问的花费是如此之高以至于一个很小的缺失率将会很快的决定运行程序的总体的AMAT。显然，我们需要尽可能的避免很多的趋势或者运行很慢，也就是产品的比例。有一个办法可以帮助就是仔细的开发一个只能策略。
###22.2 最优替换策略
为了更好的理解一个特定的替换策略是如何工作的，比较好的方式是跟最好的可能的替换策略比较。事实证明，这样一个 __最优(optimal)__ 策略由Belady在多年前开发(他在最初叫它MIN)。最优替换策略总体上导致最少的缺失数。Belady展示了一个简单的方式(但是不幸的是很难实现)，这个方式替换在 _最远的未来(furthest in the future)_ 才会被访问的页就是最优策略，导致最少可能的缓存缺失。
>tip:和最优比较是有用的
>尽管最优策略作为真实的策略不具有实用性，它在类似或者其他研究里面作为比较点及其有用。你说你的新算法命中率是80%在孤立的环境不是很有意义；如果说最优达到了82%的命中率(因此你的新方式很接近最优策略)就让结果变得更有意义并给了新算法比较环境。因此，在你进行的任何研究，知道哪个是最优让你有更好的比较，显示了还有多少提升可能，也让你知道什么时候你可以停止让策略变得更好，因为它距离理想情况足够的进。

最优策略背后的直觉是有道理的。想一下：如果你不得不抛弃某些页，为什么不抛弃那些从现在开始在最远的将来才需要的页？通过这样做，你本质上可以说所有在缓存的其他页都比这个最远的页更加重要。原因简单真实：你在引用这个最远的页前先引用其他页。

让我们最终一个简单的例子来理解最优策略做出的决定。假设一个程序访问如下的虚拟页流程：0，1，2，0，1，3，0，3，1，2，1。图22_1显示了最优策略的行为，假设缓存可以放下三个页。

![图22_1:跟踪最优策略](Figure22_1.png "跟踪最优策略")

在图中，你可以看到如下动作。不意外，开头的三个访问都是缺失的，因为缓存开始是空的状态；这样的缺失有时也叫做 __冷启动缺失(cold-start miss)__ (或者叫做 __必要缺失(compulsory miss)__)。然后我们再次访问页0和1，每次都命中缓存。最后，我们遇到另外一次缺失(页3)，但是这一次缓存是慢了；替换就要发生了！哪个页应该被替换？有了最优策略，我们检验当前缓存中每个页的未来(0,1和2)，然后看到0几乎马上被访问，1稍后被访问，然后2在未来是最后被访问的，因此最优策略就有了一个简单的选择：剔除页2，结果页0，1和3在缓存中。后面三个引用会命中，但是我们到了页2，我们在很早前被剔除了，从而遭遇了另一个缺失。这里，最优策略再一次检验了缓存中每个页的未来(0,1和3)，看到只要不是剔除页1(这个页将会被访问)，我们就可以。这个例子显示了页3被剔除了，尽管0也是一个很好的选择。最后，我们命中了页1然后这个追踪结束了。
>####附注：缓存缺失的类型
>在计算机架构的世界里，架构师有时候发现按照类型描绘缺失的特性很有用，一共有三种类型：必要(compulsory)，容量(capacity)以及冲突(conflict)缺失，有时候也叫做 __三C缺失__。__必要缺失(compulsory miss)__(或者叫 __冷启动缺失(cold-start miss)__)的发生是因为缓存在开始时是空的，这是第一次引用这些条目；相反，一个 __容量缺失(capacity miss)__ 的发生时因为缓存的空间用完了从而不得不剔除一个条目并把新的条目放到缓存中。第三类的缺失(__冲突缺失(conflict miss)__)发生在硬件，由于在硬件缓存中有限制一个条目可以放置的位置，这关系到所谓的 __组关联(set-associativity)__；这不会发生在OS页缓存，因为OS的缓存是 __全相关(fully-associative)__ 的，例如，那里没有限制一个页能够放置在内存的位置。

我们也可以计算缓存的命中率：根据6次命中和5次缺失，命中率是$\frac{Hits}{Hits+Misses}$也就是$\frac{6}{6+5}$结果是54.5%。你也可以计算命中率 _模(modulo)_ 必要缺失(例如，忽略给定页 _首次(first)_ 缺失)，结果是85.7%的命中率(注：这里的模就是排除掉每个页首次的miss，也就是只有一次miss不是必要缺失，所以就是$\frac{6}{6+1}$)

不幸的是，正如我们之前在开发调度策略时了解到，未来通常是不可知的；你没有办法为了通用目的操作系统[<sup id="content1">1</sup>](#1)构建最优策略。因此，在开发一个真实可部署的策略，我们将关注那些寻找其他方式决定哪个页被剔除的方法。最优策略将仅仅作为一个比较点，为了让我们知道我们有多接近“完美”。

###22.3 一个简单策略：FIFO
早期很多系统避免了试图接近最优的复杂性采用了简单的替换策略。例如，有些系统使用 __FIFO__(first-in,first-out)替换策略，这里页就简单的放到队列中当这些页进入系统时；当替换策略发生时，位于这个队列中的尾部的页(“先进入的”页)被剔除。FIFO有一个强项：很容易实现

让我们检查一下对于我们的例子中的引用流，FIFO是如何工作的(图22_2)。我们再一次开始我们的跟踪，首先是页0，1和2的必要缺失，然后命中了0和1。下一个，页3被引用了，导致一个缺失，使用FIFO替换策略的决定很容易：选择"第一个"页(图中的缓存状态是按照FIFO顺序保存的，首先进入的页在左边)，也就是页0。不幸的是，我们洗一次访问是页0，导致又一个缺失，然后替换(也就是页1)。然后我们命中了页3，但是缺失了1和2，然后再一次命中3。

![图22_2:跟踪FIFO策略](Figure22_2.png "跟踪FIFO策略")

比较FIFO和最优策略，FIFO显然比较糟糕：36.4%的命中率(排除掉必要缺失是57.1%)。FIFO不能确定块的重要性：甚至页0已经被访问了几次，FIFO依旧把它剔除了，仅仅因为他是第一个被放到内存中的。
>####附注：BELADY异常
>Belady(最优策略的作者)和同事找到一个有趣引用流，它的行为跟预期不一样。内存引用流：1，2，3，4，1，2，5，1，2，3，4，5。他们研究的替换策略时FIFO。有趣的部分是：当把缓存大小从3个页变成4个页时，缓存命中率是如何改变的。
>
>总的来说，你可能希望当缓存变大时，命中率会 _提升_ (变得更高)。但是在这个例子中，用了FIFO，它变得更糟糕了！可以自己计算下命中率。这个奇怪的行为通常被叫做 __Belady异常(Belady's Anomaly)__(委屈了他的合作者)。
>
>其他一些策略，例如LRU，不会遭受这个问题。你能猜到为什么？事实证明，LRU有所谓的 __栈特性(stack property)__。对于有这种特性的算法，大小$N+1$的缓存轻易的包括了大小为$N$的缓存的内容。也即，当增加缓存的大小，命中率将要么保持一样要么提升。FIFO和随机(和其他)显然没有这种栈特性，从而容易有异常的行为。
###22.4 另一个简单的策略：随机
另一个简单的替换策略是随机策略。在内存压力下，它简单的选择一个随机页来替换。随机的属性和FIFO类似；他就是简单的替换，但是他并不真的尝试变得太智能来挑选哪个块被剔除。让我们在之前的例子上看看随机是如何做的。

![图22_3 "跟踪随机策略"](Figure22_3.png "跟踪随机策略")

当然，随机如何工作完全依赖于在随机策略选择时多幸运(或多不幸运)。在上面的例子里，随机比FIFO做的要好一点，比最优策略要差一点。事实上，我们可以运行随机实现数千次并决定通常情况下是如何做的。图22_4显示了在10000实验时，随机策略完成了多少次命中，每次都有不同的随机种子。正如你看到，有时候(仅超过40%的时候)，随机和最优策略是一样好的，在上面的例子里，完成了6次命中；有时候做的更糟糕，完成2次或者更少。随机怎么做依赖于抽签时多幸运。

![图22_4 "10000次实验随机策略的性能"](Figure22_4.png "10000次实验随机策略的性能")

###22.5 使用历史：LRU
不幸的是，任何像FIFO或者随机策略那样简单的策略都有一个公共的问题：他可能剔除了一个重要的页，这个页可能会被再次引用。FIFO踢出最开始引入的页；如果这发生在一个页上面有着重要代码或者数据结构， 不管怎样都会被扔出，甚至他很快被页入回来。因此，FIFO，随机，已经类似策略并不接近最优策略，我们需要更智能的。

就像我们对于调度策略所做的，为了提升我们在未来的猜测，我们再一次依靠过去并用 _历史_ 作为我们的指引。例如，如果一个程序刚刚访问了一个页，它很有可能会在不久之后再次访问它。

页替换策略可以使用的一类历史信息是 __频率(frequency)__；如果一个页被访问了多次，可能他不应该被替换，因为他显然有某些价值。页的一个更常用属性是页访问的 __近期性(recency)__；一个页越是最近被访问过，可能它更可能将会再次被访问。

这一族策略基于人们说的 __局部性原理(principle of locality)__，这基本上是对程序和他行为的观察。这个原理说，很简单，就是程序倾向于访问某些代码序列(例如，在一个循环里)和数据结构(例如，循环访问数组)很频繁；我们应该试着使用历史来找出那个页重要，保持那些页到内存中当到了剔除时间。

>####附注：局部性的类型
>程序倾向于展示的局部性有两类。第一类是 __空间局部性(spatial locality)__，意味着如果页 _P_ 背访问了，很可能这个页附近的页(例如$P - 1$或者 $P + 1$)也会被访问。第二类是 __时间局部性(temporal locality)__，这意味着刚刚访问的页很可能在不久后再次被访问。关于这两类局部性存在的假设在硬件系统的缓存体系扮演了很大的角色，当这些局部性存在时，部署了多个指令，代码和地址转换缓存层次来帮助程序运行各个快速。
>
>当然，__局部性原理__，正如它通常的叫法，没有所有程序都必须遵守(hard-and-fast)的规则。事实上，某些程序访问内存(或者磁盘)是按照随机的方式访问的，并且在他们的内存访问流中没有展示太多或者所有的局部性。因此，局部性是一个应该保存到脑海的好事情，当设计任意类型的缓存(硬件或者软件)，他不 _保证_ 成功。当然，它是很有启发的并在计算机系统设计中通常证明很有用。

因此，一族简单的基于历史的算法出生了。__最不频繁使用(Least-Frequently-Used LFU)__ 策略替换最不频繁使用的页当需要剔除事。类似的，__最近最少使用(Least-Recently-Used LRU)__ 策略替换最近最少使用的页。这些算法很容易记，看着名字就知道他们怎么做。

为了更好的理解LRU，让我们检查一下对于我们样例引用流，LRU是如何做的。图22_5显示了结果。从图中看，你可以看到LRU是如何很使用历史的，从而相比于无状态的策略例如随机和FIFO做的更好。在这个例子里，当首次需要替换一个页，LRU剔除了页2，因为0和1最近才被访问。它然后替换页0因为1和3最近才被替换。在上面两种例子，LRU的决定，基于历史，证明是正确的，下一次引用也是命中，因此，在我们的例子里，LRU尽可能做的好，在性能上匹配上了最优策略[<sup id="content2">2</sup>](#2)。

我也应该记住还存在与之相反的算法存在：__最频繁使用(Most-Frequently-Used MFU)__ 和 __最近最多使用(Most-Recently-Used MRU)__。在大多数程序中没有使用它们。

###22.6工作集例子
为了更好理解这些策略行为，让我们看看一些例子。这里，我们将检验更复杂的 __工作集__ 而不是简单地跟踪。然而， 尽管这些工作集被大大简化；一个更好的研究需要包括应用跟踪。

我们第一个工作集没有局部性，这意味着每个引用是随机访问页集合的一个页，这个工作集访问100个独立的页(100 unique pages)，按照随机的方式选择下一个页；总体有10000个页被访问。在这个实验中，我们缓存的尺寸从很小(1个页)到足够存放全部唯一页(100个页)，为了看看随着缓存尺寸的不同每个策略的行为。

![图22_6:"没有局部性的工作集"](Figure22_6.png "没有局部性的工作集")

图22_6描绘了最优，LRU，随机和FIFO策略的事件结果。y轴显示了每个策略达到的命中率；x轴显示了缓存大小变化。

从图里我们可以总结出来几个结论。首先，当工作集没有局部性，无论你使用的什么现实策略，LRU，FIFO和随机，执行的结果都一样，命中率只由缓存大小决定。第二，当缓存大到可以容纳真个工作集，无论你使用的是什么策略，所有的策略(甚至随机策略)覆盖了100%命中率，当所有引用块都填入在缓存中。最后，你可以看看最优策略的执行显著要好于现实策略，在未来挑选，如果可能，对于替换做了更好的工作。

下一个要检验的工作集叫做"80-20"工作集，它拥抱了局部性：80%的引用由20%的页构成(“热点”页)；剩下的20%引用由剩下的80%页构成("冷"页)。在我们的工作集中，依旧一共有100个独立页；因此，“热点”页意味着占据了大多数时间，"冷"页是占据剩下的时间。图22_7显示了这个工作集策略如何执行。

![图22_7:80-20工作集](Figure22_7.png "80-20工作集")

从图中可以看到，随机和FIFO都做的挺好，LRU做的更好，因为它更可能存放了热点数据；因为那些页在过去被频繁的引用，这些页很可能会在不久的将来再次引用。最优策略再一次做的更好，显示了LRU的历史信息不是完美的。

你可能会怀疑：LRU的提升比随机和FIFO策略真的那么重要？答案是，通常，这要看情况。如果每个页缺失消耗很快(不常见)，那么尽管命中率只有很小的提升(减少缺失率)可以在性能上有巨大的不同。如果页缺失花费不高，那么LRU的好处就可能不那么重要。

让我们看看最后一个工作集。我们称之为"循环序列"工作集，在这个里面，我们在序列中引用了50个页，从0开始直到49，然后我们循环，重复这些访问，一共有访问这50个独立页10000次访问。图22_8显示了这个工作集下各个策略的行为。

![图22_8 "循环工作集"](Figure22_8.png "循环工作集")

这个工作集，常见于很多引用中(包括重要的商业应用例如数据库)，显示了LRU和FIFO最糟糕的情况。这些算法，在循环序列工作集，剔除了较老的页；不幸的是，由于这个工作集循环的本质，这些较老的页将比那些策略倾向于保存到缓存中的页要更快的被访问。事实上，甚至一个容量是49大小的缓存，一个有着50个页的循环序列工作集会导致0%命中率。有趣的是，随机策略进展的显著要更好，虽然没有接近最优策略，但至少达成了非零的命中率。证明了随机策略有某些很好的属性；这个属性没有奇怪的边界情况行为。

###22.7 实现基于历史的算法
正如你看到的，类似LRU的算法通常比想FIFO或者随机那样比较简单的策略做的要好一些，这些简单的策略可能会抛弃掉重要的页。不幸的是，基于历史的策略给我们一个新的挑战：如何实现他们？

让我们用LRU举个例子。为了完美实现它，我们需要做很多工作。具体来说，根据每次 _页访问_(例如，每次内存访问，无论是指令取或者加载或者存储)，我们必须更新某些数据结构来把页移动到列表的前端(例如，MRU端)。与FIFO对比，FIFO存放页的链表只在页被 _剔除_ 的时候才会被访问(通过删除先进入的页)或者当一个新的页被添加到链表中(加入到最后进入的那一端)。为了持续跟踪哪个页是最近最少/最多使用的，系统不得不对 _每次内存引用_ 做一些统计工作。显然，没有仔细的管理，这种统计会导致巨大的性能损失。

加速这种操作的一个方式是增加一点硬件支持。例如，每次访问页时，机器可以更新内存中的一个时间域(举例来说，这个域可能在每个进程的页表，或者是内存中某些独立的数组，数组每个条目对应系统的每个物理域)。因此，当一个页被访问了，时间域就被硬件设置为当前时间。然后，当替换一个页，OS可以简单地扫描系统中时间域查找最近最少使用的页。

不幸的是，随着系统页数的增长，扫描一个巨大数组的时间来查找绝对的最近最少使用的页花销过分高昂。想象一下内存4G的现代机器，被分割成4KB大小的页。这个机器有1百万的页，从而找到LRU需要花费很长的时间，甚至按照现代CPU的速度也是。这里就有一个问题：我们真的需要找到绝对意义上的最老的页去替换么？我们可以用一个接近的算法替代么？
>#### 问题：如何实现一个LRU替代算法
>由于实现完美的LRU比较困难，我们能不能以某种方式接近它么，依旧可以获取到想要的行为？
###22.8 接近LRU
事实证明，答案是可以的：接近LRU从计算开销的角度来看更可行的(more feasible from a computational-overhead standpoint)，而且事实上这也是很多现代系统做的事情。这个想法需要某些硬件支持，是以 __使用位(use bit)__ 的形式(有时候也叫做 __引用位(reference bit)__)，这个首先是第一个使用了分页的系统实现了，Atlas一级存储。它使用了系统每个页上的一个使用位，这个使用位存在于内存的某处(它有可能存在于每个进程的页表中，页可能是某处的数组上)。无论什么时候引用了一个页(例如，读或者写)，使用位会被硬件设置为1。硬件永远不会清理这个位(例如，设置为0)，这是OS的责任。

OS是如何用这个使用位来接近LRU？有很多实现方法，但建议使用 __时钟算法(clock algorithm)__ 这个简单的实现方式。想象一下系统所有的页排列成一个环形列表。一个 __钟针__ 指向某些特定的页作为起始处(不关心具体在哪个位置)。当发生了替换，OS检查当前指向的页 _P_ 的使用位是1还是0。如果是1，这意味着页 _P_ 最近被使用过因此它 _不是_ 一个很好的候选者。然后 _P_ 的使用位被设置为0(被清除)，然后时钟指针增加移动到下一页(_P_+1)。算法一直运行知道找到一个使用位被设置为0的页，意味着这最近这个页没有被使用(后者，最差的例子，所有的页都被使用了，现在我们搜索了整个页集合，并清理了全部的页的使用位)。

注意，这个方法不是采用使用位接近LRU唯一的方法。事实上，任何会周期性清理使用位，并通过使用位是0还是1来决定替换哪个页的方式都是可行的。Corbato的时钟算法只是比较早并获得某些成功，它还有一个好特性，即不会重复扫描整个内存来查找未使用页。

![图22_9.png "使用时钟的80-20工作量"](Figure22_9.png "使用时钟的80-20工作量")

时钟算法变体的行为如图22_9。当发生替换，这个变体随机的扫描页；当它遇到了一个页的引用位被设置为1，它清楚了这个位(例如，设置为0)；当它查找到一个页的引用位被设置为0，它选择剔除这个页。正如你看到的，他的表现不如LRU完美，但是比不考虑历史的方式要好。
###22.9 考虑脏页
对于时钟算法的通常会做一个改进(最开始也是Corabto提出来的)，增加对一个页在内存中是否被修改过的判断。原因是：如果一个页被 __修改过__ 了，那么他就是 __脏页__，那么，如果排除他，就需要把他写回到磁盘中，这个成本很高(否则他就是 __干净的__)。如果没有被修改(也就是页是 __干净的__)，那么剔除操作就很轻松；物理帧可以简单的被其他目的重用而不需要额外的I/O。因此，相对于剔除脏页某些VM系统倾向于剔除干净的页。

为了支持这个行为，硬件需要包含一个 __已修改位__(也即，__脏位__)。这个位只要页被写了就会被设置，然后就可以在页替换算法中使用了。例如，时钟算法可以修改为扫描没有使用且干净的页先排除；然后如果没有找到，那就排除未使用且是脏的页，依次顺推。

###22.10 其他VM策略
页替换策略并不是VM子系统采用的唯一策略(尽管他可能是最重要的)。例如，OS必须要决定什么时候把页 _引入_ 到内存中。这个策略，有时候也叫做 __页选择(page selection)__ 策略(由Denning开始称呼的)，给OS提供了某些不同的选择。

对大多数页，OS简单是使用 __按需页入__，这意味着OS在页被访问的时候把页带入到内存中，“按需”的意思就是这个。当然，OS可以猜到一个页是否将要被使用，然后提前把它放入到内存中，这个行为叫做 __预取(prefetching)__ 并且只有当有合理的成功机会才能被使用。 举例来说，某些系统将设如果代码页 _P_ 被放入到内存中后，代码页 _P_ +1可能将很快被访问并且也要放入到内存中。

另一个策略决定OS如何把页写入到磁盘中。当然，一次写一个页到内存没有问题，然而，很多系统会在内存收集一些等待写入的页，然后一次(更有效)的写入到磁盘。这个行为通常叫做写 __聚集(clustering)__ 或者简单的叫做写 __分组__，这个很高效，因为利用了磁盘驱动的性质：一次只执行一个大的写操作比多次小的写操作更有效。

###22.11 抖动(thrashing)
在结束之前，我们解决最后一个问题：如果内存超过配额时，OS应该做什么，并且，运行进程集合所要求的内存超过了可用物理内存？在这个情况，系统将会频繁的分页，这个条件有时候叫做 __抖动__。

某些早期的操作系统在发生抖动时有一系列公平精致的机制检测并解决它。例如，给定一个进程集合，系统可能决定不运行这个集合的一个子集合，并希望剩下的进程 __工作集__(这些进程正在使用的页)填入到内存并可以有些改善。这个方式，通常叫做 __准入控制(admission control)__，它宣称：有时候少做一些事并把事情做好比试图一次性做所有的事却做的很糟糕要好，这个场景在现代计算机系统和真实生活中都由遇到。

某些当前的系统采取了更加严苛的方式管理内存超载。例如，某些Linux版本会运行一个 __内存溢出撒杀手(out-of-memory killer)__ 当内存超配额时；这个守护进程选择一个内存不敏感进程并把它杀掉，从而以一种不太精致的方式减少内存。在成功减少了内存压力的同时，这个方式也有问题，举个例子，如果它杀掉了X服务器然后所有需要显示才能渲染的应用都不可用。

###22.12总结
我们已经看到了几种页替换(和其他)策略的介绍，它们是现代操作系统中VM子系统的一部分。现代系统对直接的LRU近似情况做了些改进比如时钟算法；例如，__扫描阻抗(scan resistance)__ 是很多现代算法的重要部分，例如ARC。扫描阻抗(scan-resistant)算法通常是类LRU的但也试图避免LRU的最差情形时的行为，我们在循环顺序工作集中看到过。因此，页替换算法的进程一直都在持续。

然而，在很多情况下，上述算法的重要性已经降低了，由于内存访问和磁盘访问时间的差异在增加。由于页入磁盘耗费很高，频繁分页(paging)是禁止的。这时，过多分页的最好解决办法通常很简单(如果智力上已经无法满足)：买更多的内存。

[<sup id="1">1</sup>](#content1)如果你可以，一定让我们知道！我们可以一起变得富有。或者就像那些发现了冷聚变的科学家，被广泛的嘲笑和轻视。
[<sup id="2">2</sup>](#content2)好的，我们加工了结果，但是为了证明观点加工结果是必要的。