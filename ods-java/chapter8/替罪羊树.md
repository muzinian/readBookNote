## 替罪羊树(scapegoat trees)
本章我们研究一个二叉搜索树数据结构，替罪羊树。这个结构基于一个常见的名言：当事情出错，人们首先会找到某个人(替罪羊)背锅。一旦过失确认了，我就让替罪羊解决问题。

`ScapegoatTree`使用 _局部重建操作(partial rebuilding operations)_ 保持自身平衡。在局部重建过程中，整个子树被解构并重建为一个完美平衡子树。将一个以节点`u`为根的子树重建为一个完美平衡树有很多方法。最简单的一种是遍历`u`的子树，把他所有节点都收集到一个数组`a`中，通过`a`递归地构建一个平衡子树。如果我们设`m=a.length/2`，那么元素`a[m]`就是新子树的根，`a[0]`到`a[m-1]`就是递归的存放在左子树中，而`a[m+1]`到`a[a.length-1]`就递归地存在右子树中。
```Java
void rebuild(Node<T> u){
    int ns = size(u);
    Node<T> p = u.parent;
    Node<T>[] a = Array.newInstance(Node.class,ns);
    packIntoArray(u,a,0);
    if(p == nil){
        r = buildBalanced(a,0,ns);
        r.parent = nil;
    }else if(p.right == u){
        p.right = buildBalanced(a,0,ns);
        p.right.parent = p;
    }else{
        p.left = buildBalanced(a,0,ns);
        p.left.parent = p;
    }
}
int packIntoArray(Node<T> u,Node<T>[]a,int i){
    if(u == nil){
        return i;
    }
    i = pakcIntoArray(u.left,a,i);
    a[i++] = u;
    return packIntoArray(u.right,a,i);
}
Node<T> buildBalanced(Node<T>[]a,int i,int ns){
    if(ns == 0){
        return nil;
    }
    int m = ns/2;
    a[i+m].left = buildBalanced(a,i,m);
    if(a[i+m].left != nil){
        a[i+m].left.parent = a[i+m];
    }
    a[i+m].right = buildBalanced(a,i+m+1,ns-m-1);
    if(a[i+m].right != nil){
        a[i+m].right.parent = a[i+m];
    }
    return a[i+m];
}
```
调用一次`rebuild()`操作会花费$O(size(u))$。产生的子树有最小的高度；不存在有$size(u)$个节点的子树高度会更小。

### 8.1 `ScapegoatTree`：使用部分重建的二叉搜索树
`ScapegoatTree`是一个二叉搜索树，并且有一个变量`n`跟踪树中节点的个数，同时还有一个计数器`q`，维护了节点个数的上界。
```Java
int q;
```
在全部时刻，`n`和`q`都满足如下不等式：
$$q/2\le n \le q$$
除此之外，`ScapegoatTree`还有对数的高度；替罪羊树的高度在所有时刻都不会超过：
$$\tag{8.1}\log_{3/2}q\le \log_{3/2} 2n \lt \log_{3/2}n+2$$

![figure8.1.png "高度为5，节点数为10的替罪羊树"](figure8.1.png "高度为5，节点数为10的替罪羊树")

即使有这个约束，`ScapegoatTree`依旧可以相当不平衡。图8.1的$q = n = 10$并且高满足$\lt \log_{3/2}{10}\approx 5.679$。

通过使用标准的`BinarySearchTree`搜索算法(参考6.2节)就实现了`ScapegoatTree`的`find(x)`操作。这个时间开销正比于树的高度，根据公式$(8.1)$，就是$O(\log n)$。

为了实现`add(x)`操作，我们首先增加`n`和`q`然后使用把一个节点`x`加入到二叉搜索树中的普通算法；我们搜索`x`然后添加一个新的叶节点`u`满足`u.x = x`。此时，我们可能很幸运：`u`的深度不超过$\log_{3/2}q$。这样，我们就完成了操作。

不幸的是，有时候会出现$depth(u)\lt \log_{3/2}q$。在这种情况中，我们需要降低它的高度。这并不是一个大工程；只有一个节点`u`的高度超过了$\log_{3/2}q$。为了修复`u`，我们从`u`转向根节点走查找一个 _替罪羊(scapegoat)_ `w`。这个替罪羊`w`是很不平衡的节点。它有这个属性：
$$\tag{8.2} \frac{size(w.child)}{size(w)}\lt \frac{2}{3}$$
这里，`w.child`是`w`两个孩子中那个位于从根节点到节点`u`路径上的节点。我们将简单的证明存在这个替罪羊。现在，我们就先使用这个结论。一旦我们找到一个替罪羊`w`，我们完全摧毁这个以`w`为根的子树并重建为一个完美平衡的二叉搜索树。从公式$(8.2)$我们可以知道，甚至在添加节点`u`前，`w`的子树也不是一个完全二叉树。因此，当我们重建`w`时，高度至少下降1，因此，`ScapegoatTree`的高度再一次至多是$\log_{3/2}q$。
```Java
boolean add(T x){
    //先做基本的插入操作保存深度
    Node<T> u = newNode(x);
    int d = addWithDepth(u);
    if(d>log32(q)){
        //深度超出了，查找替罪羊
        Node<T> w = u.parent;
        while(3*size(w)<=2*size(w.parent)){
            w = w.parent;
        }
        rebuild(w.parent);
    }
    return d>=0;
}
```
如果我们忽略查找替罪羊`w`和重建以`w`为根的子树，那么`add(x)`的运行时间就有初始的搜索决定，它会花费$O(\log q)=O(\log n)$的时间。我们稍后会在下一节使用摊还分析统计找到替罪羊以及重建的开销。

`ScapegoatTree`中`remove(x)`的实现很简单。我们查找`x`然后使用从`BinarySearchTree`中删除一个节点的普通方法删除这个节点。(注意到这永远不会增加树的高度)下一步，我们降低`n`，但是不修改`q`。最后，我们检查`q\lt 2n`，如果满足，我们重建整个树为一个完美平衡的二叉搜索树，并设置`q=n`。
```Java
boolean remove(T x){
    if(super.remove(x)){
        if(2*n<q){
            rebuild(r);
            q = n;
        }
        return true;
    }
    return false;
}
```
再一次，如果我们忽略重建的开销，`remove(x)`操作运行时间正比于树的高度，因此是$O(\log n)$。

![figure8.2.png](figure8.2.png)
(在`ScapegoatTree`中插入3.5导致树的高度增加为6，违反了公式$(8.1)$，因为$6\lt \log_{3/2}11\approx 5.914$。替罪羊就是包含了值5的节点)

### 8.1.1 正确性和运行时间分析
本节，我们分析`ScapegoatTree`的正确性和摊还运行时间。我们首先通过证明当`add(x)`操作会导致一个节点违反了条件$(8.1)$，那么我们总是可以找到一个替罪羊来证明正确性：
__引理8.1__ 设`u`是`ScapegoatTree`中深度$h\lt \log_{3/2}q$的一个节点。那么那么存在一个节点`w`位于从`u`到根的路径上满足：
$$\frac{size(w)}{size(parent(w))}\gt \frac{2}{3}$$
_证明_ 假设，为了矛盾，没有情况这种情况，并且，对于所有位于从节点`u`到根节点路径上的节点`w`，都有：
$$\frac{size(w)}{size(parent(w))}\lt \frac{2}{3}$$
记从根到`u`的路径为$r=u_0,\ldots,u_h=u$。那么，我们有$size(u_0)=n,size(u_1)\le \frac{2}{3}n,size(u_2)\le \frac{4}{9}n$，以及，更一般的：
$$size(u_i)\le(\frac{2}{3})^in$$
但这就导致了矛盾，因为`size(u)\ge 1`，因此
$$1\le size(u)\le (\frac{2}{3})^hn\lt(\frac{2}{3})^{\log_{3/2}q}n\le(\frac{2}{3})^{\log_{3/2}n}n=(\frac{1}{n})n=1\square$$
接下来，我们分析还没有统计的运行时间部分。这里有两部分：当搜索替罪羊节点时调用`size(u)`的开销以及当我们找到替罪羊`w`时调用`rebuild(w)`时的开销。对`size(u)`调用的开销和`rebuild(w)`调用的开销有关系，如下：
__引理8.2.__ 在`ScapegoatTree`中调用`add(x)`期间，找到一个替罪羊`w`并以`w`为根重建子树的开销是$O(size(w))$。(During a call to `add(x)` in a `scapegoatTree`,the cost of finding the scapegoat `w` and rebuilding the subtree rooted at `w` is $O(size(w))$.)

_证明_ 一旦我们找到替罪羊节点`w`，那么以它为根重建的开销就是`O(size(w))`。当我们搜索这个替罪羊节点时，我们对节点序列$u_0,\ldots,u_k$每个节点调用`size(u)`知道找到替罪羊$u_k=w$。然而，因为$u_k$是这个序列中是替罪羊节点中的第一个节点($u_k$is the first node in this sequence that is a scapegoat)，我们知道对于所有$i\in\{0,\ldots,k-2\}$都有
$$size(u_i)\lt \frac{2}{3}size(u_{i+1})$$
因此，所有对`size(u)`调用的开销总和是：
$$\begin{aligned}
    O\left(\sum_{i=0}^{k}size(u_{k-i})\right)&=O\left(size(u_k)+\sum_{i=0}^{k-1}size(u_{k-i-1})\right)\\
    &=O\left(size(u_k)+\sum_{i=0}^{k-1}\left(\frac{2}{3}\right)^isize(u_k)\right)\\
    &=O\left(size(u_k)\left(1+\sum_{i=0}^{k-1}\left(\frac{2}{3}\right)^i\right)\right)\\
    &=O(size(u_k))=O(size(w)),
\end{aligned}$$
最后一行遵循这个事实：求和值是几何级数下降序列。

剩下的就是证明在`m`个操作序列中对`rebuild(u)`的全部调用开销的上界。

__引理8.3.__ 从一个空的`ScapegoatTree`开始，任意顺序对`add(x)`和`remove(x)`操作的$m$调用会导致最多$O(m\log m)$的时间用来执行`rebuild(u)`操作。

$\text{证明}$ 为了证明这个，我们使用 _信用模式(credit scheme)_。我们想象每个节点存放一定数量的信用值。每个信用值可以支付固定数量(`c`)个单位时间供重建使用(Each credit can pay for some constant,`c`,units of time spent rebuilding)。这个模式一共给出了$O(m\log m)$个信用值，并且每次对`rebuild(u)`的调用都由这些存放在`u`上的信用值支付了。

在增加或者删除期间，我们给所有在插入或者删除节点`u`路径上的每个节点一个信用值。这样每个操作我们最多交出了$\log_{3/2}1\le \log_{3/2}m$。在删除时我们也在"别处"存放一个额外的信用值。因此，我们最多给出了$O(m\log m)$个信用值。剩下的就是证明这些信用值足够支付所有对`rebuild(u)`调用花费的时间。

如果我们是在插入时调用`rebuild(u)`，那么是因为`u`是一个替罪羊。假设，不失一般性，有：
$$\frac{size(u.left)}{size(u)}\gt \frac{2}{3}$$
使用这个事实：
$$size(u) = 1+size(u.left)+size(u.right)$$
我们可以推导出：
$$\frac{1}{2}size(u.left)>size(u.right)$$
因此：
$$size(u.left)-size(u.rigth)\gt \frac{1}{2}size(u.left)\gt \frac{1}{3}size(u)$$
现在，在包含了`u`的子树最后一次被重建的时候(又或者在`u`被插入时，如果包含`u`的子树没有重建)，我们有:
$$size(u.left)-size(u.right)\le 1$$
因此，从那时起(上一段说的时刻)，会`u.left`或者`u.right`的`add(x)`和`remove(x)`操作的数量至少是：
$$\frac{1}{3}size(u)-1$$
并且，在节点`u`是至少存放了这么多的信用值可以用来支付调用`rebuild(u)`时$O(size(u))$的时间开销。

如果我们在删除时调用`rebuild(u)`，那就是因为$q\gt 2n$。在这种情况中，我们有$q-n\gt n$个信用值在一边存放着，我们可以用这些信用值来支付重建根使用的$O(n)$时间开销。这就完成了证明。

#### 8.1.2 总结
下面的定理总结了`ScapegoatTree`数据结构的性能：

__定理8.1.__ `ScapegoatTree`实现了`SSet`接口。忽略`rebuild(u)`操作的开销，`ScapegoatTree`支持$O(\log n)$的`add(x)`,`remove(x)`和`find(x)`操作。

进一步的，从一个空的`ScapegoatTree`开始，任意$m$次对`add(x)`和`remove(x)`操作的调用会导致一共有$O(m\log m)$的时间开销用于对所有`rebuild(u)`操作的调用。

### 8.2 讨论和联系
词语 _替罪羊树(scapegoat tree)_ 是Galperin和Rivest提出的，他们定义和分析了这些树。但是Andersson在更早的时候就发现了相同的结构，他叫它们为 _一般平衡树(general balanced trees)_ 因为它们可以是任意的形状，只要高度很小就可以了。

对`ScapegoatTree`的实验性实现会揭露(reveal)出它通常远慢于本树其它`SSet`实现。这可能会让人惊讶，因为高是由
$$\log_{3/2}q\approx 1.709\log n +O(1)$$
界定的。它比`Skiplist`的搜索路径的期望长度要好并且和`Treap`相差不多。可以通过显式的在每个节点存储子树大小亦或者重用已经计算过的子树大小来优化实现(练习8.5和8.6)。尽管有这些优化，`ScapegoatTree`执行`add(x)`和`delete(x)`操作序列花费的时间也要长于其它`SSet`实现。

性能的差距是由于这个事实：不像本树讨论的其它`SSet`实现，`ScapegoatTree`会花费大量的时间重构自身。练习8.3要求你证明在`ScapegoatTree`中`n`个操作序列调用的`rebuild(u)`会花费同等的$n\log n$的时间。这同本书中讨论的其它`SSet`实现是相反的，它们在`n`个操作序列中只会花费$O(n)$的时间进行结构修改。因此，不幸的是，这个事实的一个结论就是`ScapegoatTree`通过调用`rebuild(u)`完成它所有的重构工作。

不考虑它性能上的缺乏，`ScapegoatTree`在某些应用上还是正确的选择。如果在执行旋转时，与节点相关联的数据无法在常量时间完成更新，但是可以在`rebuild`操作期间更新完时，那么，在这种情况下，`ScapegoatTree`及其基于部分重建的结构就是可以工作。练习8.11就是这样一个例子。