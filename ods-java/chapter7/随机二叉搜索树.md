## 随机二叉搜索树
本章，我们会展示一个二叉搜索树，它使用随机性来达到所有操作都有$O(\log n)$的期望运行时间

### 7.1 随即二叉搜索树
考虑如图7.1的两个二叉搜索树，每个树的节点都有$n=15$个节点。左边是一个list而右边是一个完美平衡的二叉搜索树。左边的高度是$n-1=14$，右边的高度是3。

![figure7.1.png "包含了整数0,...,14的两个二叉搜索树"](figure7.1.png "包含了整数0,...,14的两个二叉搜索树")

想象一下可能的构造方式。如果我们从一个空的`BinarySearchTree`开始，按照下面的方式添加元素，会出现左边的情况：
$$\langle0,1,2,3,4,5,6,7,8,9,10,11,12,13,14\rangle$$
其他别的添加顺序都不会构造出这个树(你可以通过对`n`进行归纳证明)。另一方面，右边的树可以按照下面的添加序列构建：
$$\langle7,3,11,1,5,9,13,0,2,4,6,8,10,12,14\rangle$$
其它序列可以工作的很好，包括：
$$\langle7,3,1,5,0,2,4,6,11,9,13,8,10,12,14\rangle$$
和
$$\langle7,3,1,11,5,0,2,4,6,9,13,8,10,12,14\rangle$$
事实上，一共有21,964,800种不同的添加序列可以生成右边的树，但是只有一个方式可以生成左边的树。

上面的例子给出了某些轶事证据表明，如果我们选择$0,\ldots,14$的一个随机排列，然后添加到二叉搜索树中，那么我们很可能会得到一个很平衡的树(图7.1右边)。

可以通过研究随机二叉搜索树我们可以形式化这个概念。一个 _随机二叉搜索树(random binary search tree)_ 的大小$n$通过如下方式获取：取整数集$0,\ldots,n-1$一个随机排列：$x_0,\ldots,x_{n-1}$，然后一个一个的把它的元素加入到`BinarySearchTree`中。对于 _随机排列(random permutation)_ 我们的意思是：$0,\ldots,n-1$的$n!$个排列(顺序)每个的可能性是相等的，因此取任意一个特定排列的可能性是$1/n!$。 

注意到值$0,\ldots,n-1$可以替换为任意包含$n$个元素的有序集合而不会改变随机二叉搜索树的性质。元素$x\in \{0,\ldots,n-1\}$就简单的代表了在大小为$n$的有序集合中排$x$名次的元素。

在我们展示随机二叉搜索树的主要结论前，我们必须花点时间稍微离题一下，去研究一下当研究随机化的结构时，经常会出现的数字类型。对于一个非负整数$k$，第$k$个 _调和数(harmonic number)_，记为$H_k$，的定义是：
$$H_k = 1+1/2+1/3+\cdots+1/k$$
调和数$H_k$没有一个简单的接近的形式(closed form)，但是但是它和$k$的自然对数很相关。特别的：
$$\ln k \lt H_k \le \ln k +1$$
学习过微积分的读者可能注意到这是因为积分$\int _1^k(1/x)\mathrm{d}x = \ln k$。记住，这个积分可以解释为一个曲线和X轴之间的区域，值$H_k$的上下界分别可以由积分$\int_1^k(1/x)\mathrm{d}x$和$1+\int_1^k(1/x)\mathrm{d}x$界定。(图7.2是一个图形化解释。)

![figure7.2.png](figure7.2.png)
(注：第`k`个调和数$H_k=\sum_{i=1}^k1/i$是两个积分的上下界。这些积分的值可以通过计算阴影面积得到，而$H_k$的值这是矩形面积)

__引理7.1.__ 大小为$n$的随机二叉搜索树中，保持如下语句所说特性：
1. 对于任意$x\in\{0,\ldots,n-1\}$，`x`的搜索路径的期望长度是$H_{x+1}+H_{n-x}-O(1)$[<sup id="content1">1</sup>](#1)
2. 对于任意$x\in (-1,n)\setminus\{0,\ldots,n-1\}$，对于元素`x`的搜索路径的期望长度是$H_{\lceil x\rceil}+H_{n-\lceil x\rceil}$($\setminus$表示补集)

下一节我们将证明这个引理。现在，考虑一下引理7.1的两个部分告诉了我们什么。第一条告诉我们如果我们在大小为`n`的树中搜索一个元素，那么搜索路径的期望长度最多是$2\ln n+O(1)$。第二条告诉了我们同样的事情在搜索树中不存在的元素时(这句话的意思是，第二条也是告诉我们在一个树中查找一个元素时的时间，只不过第二条是针对元素不在树中的)。当我们比较引理中的两个部分时，我们看到元素在树中比元素不在树中时，搜索速度只是稍微快了些。

#### 7.1.1 引理7.1的证明
证明引理7.1的关键观察是：在一个二叉搜索树$T$中，值$x$(位于开区间$(-1,n)$内)的搜索路径包含一个节点，它的key是`i`，且$i\lt x$，当且仅当用来构建树$T$的随机排列中，`i`出现在${i+1,i+2,\ldots,\lfloor x\rfloor}$中任意一个元素前。(注：这里的i位于任意${i+1,i+2,\ldots,\lfloor x\rfloor}$之前指的是，在随机排列中，任何比$i$大比$x$小的数字都要位于$i$之后，而不用关心这些数字之间的顺序，同时，在$i$之后的数字也有比$i$小的，但是比$i$大的必须要在$i$之后。参见上面列出的排列例子给出的最后一个排列情况。11位于14的搜索路径上，因为所有比11大的数据(12,13)都在11后面(但是12，13不是顺序的)，12就不在14的搜索路径上，因为13在12前面)

![figure7.3.png](figure7.3.png)
(注：当且仅当$i$是在$\{i,i+1,\ldots,\lfloor x\rfloor\}$中第一个添加到树中的元素时，值$i\lt x$存在于$x$的搜索路径上)

为了观察到这个，我们查看一下图7.3，注意到直到某个位于$\{i,i+1,\ldots,\lfloor x\rfloor\}$的元素被添加前，在开区间$(i-1,\lfloor x\rfloor +1)$中的每个元素的搜索路径都是相同的(记住，对于两个元素有两个不同的搜索路径，在树中必存在某个元素和他们相比完全不同)。设$j$是$\{i,i+1,\ldots,\lfloor x\rfloor\}$中第一个出现在随机排列中的元素。注意到$j$现在以及将来总会位于$x$的搜素路径上。如果$j\neq i$，那么包含$j$的节点$u_j$比包含$i$的节点$u_i$先创建。稍后，当$i$被添加，它就会加入到以$u_j.left$为根的子树中，因为$i<j$。另一方面，$x$的搜索路径中永远不会访问这个子树，因为在访问$u_j$节点后，就处理了$u_j.right$子树。

类似的，对于$i\gt x$，$i$出现在$x$的搜索路径上，当且仅当，$i$在用于构建树$T$的随机排列中出现在任意$\{\lceil x\rceil,\lceil x\rceil+1,\ldots,i-1\}$前。(和上一段类似，例如$i=5$，对于$x=2$的搜索路径上，{2,3,4}这个集合中3位于5前(2，3，4这个三值本身的排列顺序不影响)，所以，5就不再搜索路径上。而对于$i=3$，{2}这个集合中3位于他之前，尽管3和2之间还有很多比2小比3大的值但是不影响，3在搜索路径上)

(注：这里稍微整理理解下，整个这个观察强调的是现在有一个元素值`x`，它是根据某个排列(设为$P$)构造的树中的一个节点的key。一个值$i$(这个值$i$本身满足$i\lt x$)注意，这个$i$也是在这个排列中的，如果$i$在$x$的搜索路径之中，它就需要满足对于所有属于范围${i+1,i+2,\ldots,\lfloor x\rfloor}$的值，如果它们也出现在构造树的随机排列中，这些值在随机排列中的位置就需要位于$i$之后，只有这样，$i$才会位于$x$的搜索路径中，否则$i$就不会在$x$的搜索路径中。为什么$i$需要满足这个条件才能出现在$x$的搜索路径上，当$\{i,i+1,\ldots,\lfloor x\rfloor\}$的元素中出现在排列$P$的元素都还没有加入到树中，那么，在开区间中$(i-1,\lfloor x\rfloor +1)$中的元素的搜素路径是一样的，原因是，开区间的元素还没有加入到树中，当开区间中元素的一个元素加入到树中，搜索路径的前缀是一一致的。那么当在$\{i,i+1,\ldots,\lfloor x\rfloor\}$的元素加入到树中后，如果此时$j\neq i$，那么必然$j \gt i$，后面，再加入$i$时，$i$在$j$的左子树中，$x$在$j$的右子树中。)

注意，如果我们从$\{0,\ldots,n\}$的一个随机排列开始，那么只包含$\{i,i+1,\ldots,\lfloor x \rfloor\}$和$\{\lceil x\rceil,\lceil x\rceil +1,\ldots,i-1\}$子序列也是相应的元素的随机排列。那么，每个在子集合$\{i,i+1,\ldots,\lfloor x \rfloor\}$和$\{\lceil x\rceil,\lceil x\rceil +1,\ldots,i-1\}$中的元素都同样可能比其他任何在子集合元素要先在用于创建$T$的随机排列中出现。所以我们有：
$$\mathrm{Pr}\{i \text{位于$x$的搜索路径上}\}=\begin{cases}
    1/(\lfloor x\rfloor -i+1)\text{ 如果$i\lt x$}\\
    1/(\lceil x\rceil -i+1)\text{ 如果$i\gt x$}
\end{cases}$$

使用这个观察，引理7.1的证明涉及到某些使用了调和数的计算。

$\text{引理7.1的证明}$ 设$I_i$是指示器随机变量，当$i$出现在$x$的搜索路径上是1，否则是0。那么搜索路径的长度由如下给出：
$$\sum_{i\in\{0,\ldots,n-1\}\setminus \{x\}}I_i$$
所以，如果$x\in\{0,\ldots,n-1\}$，搜索路径的期望长度有如下给出：

![figure7.4.png "一个元素在x的搜索路径上的概率(a)x是一个整数并且(b)当x不是整数"](figure7.4.png "一个元素在x的搜索路径上的概率(a)x是一个整数并且(b)当x不是整数")

(参考图片7.4.a)
$$\begin{aligned}
    \mathrm{E}\left[\sum_{i=0}^{x-1}I_i+\sum_{i=x+1}^{n-1}I_i\right]&=\sum_{i=0}^{x-1}\mathrm{E}[I_i]+
    \sum_{i=x+1}^{n-1}\mathrm{E}[I_i]\\
    &=\sum_{i=0}^{x-1}1/(\lfloor x\rfloor-i+1)+\sum_{i=x+1}^{n-1}1/(i-\lceil x\rceil+1)\\
    &=\sum_{i=0}^{x-1}1/(x-i+1)+\sum_{i=x+1}^{n-1}1/(i-x+1)\\
    &=\frac{1}{2}+\frac{1}{3}+\cdots+\frac{1}{x+1}\\
    &\quad+\frac{1}{2}+\frac{1}{3}+\cdots+\frac{1}{n-x}\\
    &=H_{x+1}+H_{n-x}-2.
\end{aligned}$$

对于搜索一个值$x\in(-1,n)\setminus\{0,\ldots,n-1\}$的对应的计算几乎是一样的(参见图7.4.b)。

#### 7.1.2 总结
如下定理总结随即二叉搜索树的性能：

__定理7.1__ 随机二叉搜索树可以在$O(n\long n)$的时间内构造。在随即二叉搜索树中，`find(x)`的执行会花费$O(\log n)$的期望时间。

我们再次强调定理7.1的期望是因为用于构造随机二叉搜索树的随机排列。特别的，它不依赖于对`x`的随机选择，对`x`的所有值他都是真的。

### 7.2 `Treap`：随机化的二叉搜索树
当然，随即二叉搜索树的问题是它们不是动态的。它们不支持实现`SSet`接口要实现的`add(x)`和`remove(x)`操作。本节，我们描述一个叫做`Treap`的数据结构，它使用了引理7.1实现了`SSet`接口。[<sup id="content2">2</sup>](#2)

`Treap`中的一个节点很想`BiarySearchTree`中的一个节点，有一个数据值`x`，但它还包含一个唯一的数字类型的 _优先级(priority)_，`p`，是随机赋值的：
```Java
class Node<T> extends BSTNode<Node<T>,T>{
    int p;
}
```
除了是一个二叉搜索树，`Treap`中的节点还满足 _堆属性(heap property)_ ：
* (堆属性)对于每个节点`u`，除了根节点，`u.parent.p<u.p`。
换句话说，每个结点的优先级都小于它的两个孩子。图7.5展示了一个例子。

![figure7.5.png "包含值0,...,9的一个Treap例子。每个节点表示为一个包含了u.x,u.p的框"](figure7.5.png "包含值0,...,9的一个Treap例子。每个节点表示为一个包含了u.x,u.p的框")

堆和二叉搜索树的条件一起保证了，一旦每个结点的key(x)和优先级(p)确定了，`Treap`的形状就完全确定了。堆属性告诉我们属性值最小的节点就是`Treap`的根。二叉搜索树的属性告诉我们所有key值小于`r.x`的节点存放在以`r.left`为根的子树，所有key值大于`r.x`的节点存放在以`r.right`为根的子树中。

关于`Treap`中的优先级重要的一点是它们都是唯一且是随机赋值的。由于这个原因，我们有两个等价的方式看待`Treap`。正如上面的定义，`Treap`遵循堆和二叉搜索树属性。另一个说法，我们可以把`Treap`看作是一个`BinarySearchTree`，他的节点是按照优先级递增的顺序添加的。举个例子，图7.5中的`Treap`可以按照下面的`(x,p)`值序列加入到`BinarySearchTree`中产生：
$$\langle(3,1),(1,6),(0,9),(5,11),(4,14),(9,17),(7,22),(6,42),(8,49),(2,99)\rangle$$
由于优先级是随机选择的，这等同于是采用了key的随机排列，在这个例子中，排列是：
$$\langle 3,1,0,5,9,4,7,6,8,2 \rangle$$
然后将他们添加到`BinarySearchTree`中。但这意味着这个`treap`的形状和这个随机二叉搜索树是一样的。具体的说，如果我们通过节点的排序位置[<sup id="content3">3</sup>](#3)替换它们的key，那么引理7.1可以引用在这里。用`Treap`重申引理7.1，我们有：
__引理7.2__ 在`Treap`中我们存储一个由$n$个key组成的集合，它有如下属性：
1. 对于任意$x\in S$，$x$搜索路径的期望长度是$H_{r(x)+1}+H_{n-r(x)}-O(1)$
2. 对于任意$x\notin S$，$x$搜索路径的期望长度是$H_{r(x)}+H_{n-r(x)}$
这里，$r(x)$记为$x$在集合$S\cup \{x\}$中排序位置。

引理7.2告诉我们`Treap`可以高效的实现`find(x)`操作。然而，`Treap`真正的好处是它可以支持`add(x)`和`delete(x)`操作。为了做到这个，他需要执行旋转从而维护堆属性。参考图7.6。二叉搜索树中旋转是一个局部修改，它会调整节点间的父子关系，原来`u`是`w`的父节点，变成`w`的父节点`u`，同时还维护了二叉搜索树的属性。旋转有两个方式：根据`w`是`u`的右孩子还是左孩子相应的执行 _左旋转_ 和 _右旋转_ 。

![figure7.6.png "二叉搜索树中的左旋和右旋"](figure7.6.png "二叉搜索树中的左旋和右旋")

实现旋转的代码需要处理这两种可能性，并且要仔细对待边界条件(此时`u`是根节点)，因此，实际的代码要比图7.6让读者以为的长：
```Java
void rotateLeft(Node u){
    Node w = u.right;
    w.parent = u.parent;
    if(w.parent != nil){
        if(w.parent.left == u){
            w.parent.left = w;
        }else{
            w.parent.right = w;
        }
    }
    u.right = w.left;
    if(u.right != nil){
        u.right.parent = u;
    }
    u.parent = w;
    w.left = u;
    if(u==r){
        r = w;
        r.parent = nil;
    }
}
void rotateRight(Node u){
    Node w = u.left;
    w.parent = u.parent;
    if(w.parent != nil){
        if(w.parent.left == u){
            w.parent.left = w;
        }else{
            w.parent.right = w;
        }
    }
    u.left = w.right;
    if(u.left != nil){
        u.left.parent = u;
    }
    u.parent = w;
    w.right = u;
    if(u == r){
        r = w;
        r.parent = nil;
    }
}
```
就`Treap`数据结构来说，旋转最重要的属性就是`w`的深度减一而`u`的深度加一。
```Java
boolean add(T x){
    Node<T> u = newNode();
    u.x = x;
    u.p = rand.nextInt();
    if(super.add(u)){
        bubbleUp(u);
        return true;
    }
    return false;
}

void bubbleUp(Node<T> u){
    while(u.parent != nil && u.parent.p>u.p){
        if(u.parent.right == u){
            rotateLeft(u.parent);
        }else{
            rotateRight(u.parent);
        }
    }
    if(u.parent == nil){
        r = u;
    }
}
```
图7.7展示了一个`add(x)`操作的例子。

![figure7.7.png "在图7.5中的Treap中加入值"](figure7.7.png "在图7.5中的Treap中加入值")

`add(x)`操作的运行时间是由两部分组成：沿着`x`搜索路径前行的时间加上为了向上移动新添加的节点`u`到`Treap`中正确位置要执行的旋转次数。根据引理7.2，搜索路径的期望长度最多是$2\ln n+O(1)$。进一步的，每次旋转都会降低`u`的深度。当`u`变成根时才会停止，因此，旋转的期望数不能超过搜索路径的期望长度。因此，`Treap`中的`add(x)`操作是$O(\log n)$。(习题7.5要求你证明一次新增操作期间旋转的期望执行次数实际上只是$O(1)$。)

`Treap`的`remove(x)`操作是`add(x)`操作的反面。我们搜索包含`x`的节点`u`，然后执行旋转节点`u`，移动它直到它变成一个叶子，然后我们从`Treap`中把`u`移走。注意，为了向下移动`u`，我们可以对`u`执行左旋转或者右旋转，对应的会使用`u.right`或`u.left`替换`u`。选择向哪边旋转由下面的规则判定：
1. 如果`u.left`和`u.right`都是`null`，那么`u`是一个叶子，所以不需要旋转。
2. 如果`u.left`(或者`u.right`)是`null`，那么就相应地在`u`执行右旋转(或者左旋转)。
3. 如果`u.left.p<u.right.p`(`u.left.p>u.right.p`)那么就相应地在`u`执行右旋转(或者左旋转)。
这三个规则保证了`Treap`不会变得不能连接，并且一旦`u`被删除，堆属性就恢复了。
```Java
boolean remove(T x){
    Node<T> u = findLast(x);
    if(u != nil && compare(u.x,x)==0){
        trickleDown(u);
        splice(u);
        return true;
    }
    return false;
}
void trickleDown( Node<T> u){
    while(u.left != nil || u.right != nil){
        if(u.left == nil){
            rotateLeft(u);
        }else if(u.right == nil){
            rotateRight(u);
        }else if(u.left.p < u.right.p){
            rotateRight(u);
        }else{
            rotateLeft(u);
        }
        if(r == u){
            r = u.parent;
        }
    }
}
```
图7.8展示了一个`remove(x)`操作的例子。

![figure7.8.png "从图7.5中的Treap中删除值9"](figure7.8.png "从图7.5中的Treap中删除值9")

#### 7.2.1 总结
如下定理总结了`Treap`数据结构的性能：
__定理7.2__ `Treap`实现了`SSet`接口。`Treap`支持`add(x)`，`remove(x)`和`find(x)`操作，每个操作期望运行时间是$O(\log n)$。

很有必要比较`Treap`和`SkiplistSSet`这两种数据结构。它们都实现了$O(\log n)$期望运行时间的`SSet`操作。在这两个数据结构中，`add(x)`和`remove(x)`都涉及到涉及到搜索以及常量时间的指针修改(参考练习7.5)。因此，对于这两种数据结构，搜索路径的期望长度就是评估他们性能的关键值。在`SkiplistSSet`中，搜索路径的期望长度是
$$2\log n+O(1)$$
在`Treap`中，搜索路径的期望长度是：
$$2\ln n +O(1)\approx 1.386\log n+O(1)$$
因此，`Treap`的搜索路径还是相当短的，这转化为在`Treap`中比`Skiplists`操作明显的快。第四章的练习4.7证明了`Skiplist`的搜索路径期望长度可以通过使用有偏向的硬币抛掷化简到
$$e\ln n+O(1)\approx 1.884\log n +O(1)$$
甚至使用了优化，`SkiplistSSet`中搜索路径的期望长度还是明显的长于`Treap`。

分析`remove(x)`操作运行时间的技巧是观察到这个操作逆转了`add(x)`操作。具体地说，如果我们使用同样的优先级`u.p`重新再插入`x`，那么`add(x)`操作会执行完全一致的旋转次数，并且`Treap`会恢复成跟发生`remove(x)`操作前完全一样的状态。(从下往上看，图7.8展示了值9插入到`Treap`中的操作。)这意味着大小为`n`的`Treap`的`remove(x)`操作的期望运行时间正比于大小为`n-1`的`Treap`的`add(x)`操作的期望运行时间。我们总结到`remove(x)`的期望运行时间是$O(\log n)$。


使用旋转，我们可以一如下方式实现`add(x)`操作：我们创建一个新节点`u`，赋值`u.x = x`，然后挑选一个随机值赋给`u.p`。下一步，我们`BinarySearchTree`的`add(x)`算法把节点`u`加到`Treap`中，这样`u`就变成了`Treap`的一个节点。这个时候，我们的`Treap`满足了二叉搜索树的性质。具体地说，它可能会导致`u.parent.p>u.p`。如果出现了这种情况，那么我们就在`w=u.parent`这个节点执行旋转，这样，`u`就变成了`w`的父节点。如果`u`依旧违反了堆属性，我们重复这个操作，每次对`u`的深度减一，直到`u`要么变成根节点要么满足`u.parent.p<u.p`。

### 7.3 讨论和练习
随机二叉搜索树已经被广泛的研究。Devroye给出了引理7.1的一个证明以及相关结论。在很多论文中还展示了很多更强的结论，其中最令人影响深刻的要归于Reed，他证明了随机二叉搜索树的高度是
$$\alpha \ln n-\beta \ln\ln n+O(1)$$
这里$\alpha\approx 4.31107$，它是开区间内$[2,\infin)$等式$\alpha \ln((2e/\alpha))=1$和$\beta=\frac{3}{2\ln(\alpha/2)}$的唯一解。进一步的，高度的变化是常量(the variance of the height is constant，这里不知道variance是不是方差，但大概率不是，没有涉及到概率计算)。

Seidel和Aragon创造了`Treap`这个名字，他们讨论了`Treap`以及其变体。然而，它们的基本结构很早就被Vuillemin研究了，他称这些为 Cartesian trees。

`Treap`数据结构的一个可能的空间优化是消除在每个节点显式的存储优先级`p`。相反，节点`u`的优先级是通过对`u`的内存地址进行哈希计算得到的(在Java中，这等价于哈希`u.hashCode()`)。尽管在实践中，有很多哈希函数可以工作的很好，但是为了让引理7.最重要的一部分保持有效，哈希函数必须要随机并且能够 _最小独立属性(min-wise independent property)_：对于任意唯一的值$x_1,\ldots,x_k$，每个值的哈希值是$h(x_1),\ldots,h(x_k)$应该是有很高概率的唯一，并且，对于每个$i\in\{1,\ldots,k\}$，
$$\mathrm{Pr}\{h(x_i)=\min\{h(x_1),\ldots,h(x_k)\}\}\le c/k$$
对于某个常数$c$。这种类型的哈希函数中 _tabulation hashing_ 一个很容易实现并且相当快速的哈希函数。

另一个不存放每个节点优先级的`Treap`变体是Martínez和Roura的随机化的二叉搜索树。在这个变体中，每个节点`u`，存放了以`u`为根的子树大小`u.size`。`add(x)`和`remove(x)`操作都是随机化的。将`x`加入到以`u`为根的子树的算法如下：
1. 如果概率是$1/(size(u)+1)$，那么值`x`就按照一般的方式被添加为叶子，然后完成旋转把`x`提升为子树的根
2. 否则(概率等于$1-1/(size(u)+1)$)，值`x`被递归地恰当地加入到以`u.left`或`u.right`为根的子树中。

第一个情况对应于在一个`Treap`中执行一个`add(x)`操作，此时，`x`的节点接受到的随机优先级`u`的子树中任意`size(u)`的优先级，这种情况发生的概率是一样的。

从一个随机二叉搜索树中删除一个值`x`和从`Treap`中删除一个元素类似。我们找到包含`x`的节点`u`，然后重复执行旋转并增加`u`的深度直到他变成一个叶子，此时我们可以从树中移除它。每一步中随机选择是执行左旋转还是右旋转。
1. 如果概率`u.left.size/(u.size-1)`，我们在节点`u`执行一次右旋转，让`u.left`变为之前根是`u`的子树的根。
2. 如果概率是`u.right.size(u.size-1)`，我们在节点`u`执行一次左旋转，让`u.right`变为之前根是`u`的子树的根。
再一次，我们可以很容易的验证它和`Treap`中删除算法执行左旋转或右旋转的概率是完全一样的。

随机化的二叉搜索树相比于treaps有劣势，那就是当添加和删除元素时它们会做很多随机决策，并且它们必须要维护子树的大小。相比于treaps，随机化的二叉搜索树的一个优势是子树大小可以服务于其它有用的目的，比如，以$O(\log n)$的期望时间提供按照排名访问的功能(参见练习7.10)。相比来说，存在treap节点中的随机属性除了保持treap的平衡外没有其它用处。

[<sup id="1">1</sup>](#content1) 表达式$x+1$和$n-x$可以分别解释为树中小于等于`x`的元素个数和树中大于等于`x`的元素个数。
[<sup id="2">2</sup>](#content2) `Treap`这个名字来自于这个事实：这个数据结构是模拟的二叉搜索树(__T__ ree)(6.2节)和堆(h __eap__)(第十章)。
[<sup id="3">3e</sup>](#content3) 元素`x`在集合$S$中排名就是集合$S$中小于`x`的个数。