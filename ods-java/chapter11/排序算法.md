## 排序算法
本章讨论对`n`个元素排序的算法。这个主题看起来对于一个主题是数据结构的书来说很奇怪，但是有很多好的理由将这一主题包含在本书中。最显然的原因是这些算法中有两个算法(快速排序和堆排序)和我们已经学过的两个数据结构密切相关(分别是随机二叉搜索树和堆)。

本章第一部分讨论的算法只使用比较进行排序，并且提供三个运行时间是$O(n\log n)$的算法。事实证明，所有三个算法都是渐进最优的(asymptomatically optimal)；对于只使用比较的算法都无法避免在最差情况下大概$n\log n$次的比较，甚至在平均情况也是这样。

在继续前，我们应该注意到前面章节介绍的任意`SSet`或者优先队列实现都可以获得一个$O(n\log n)$时间的排序算法。例如，我们可以通过先在`BinaryHeap`或者`MeldableHeap`中执行`n`次`add(x)`操作，然后再执行`n`次`remove()`操作对`n`个元素排序。我们也可以对任意二叉搜索树执行`n`次`add(x)`操作并通过中序遍历已排好序的方式提取元素。然而，在这些例子中，我们都要构造一个基本没有使用的数据结构，这样成本太高。排序是如此的重要值得研究尽可能快的，简单的，空间高效的直接方法。

本章第二部分证明了，如果我们允许除了比较外还有其它操作，那么就可以打破这个限制。事实上，通过使用数组索引方式，可以在$O(cn)$的时间排序值在范围$\{0,ldots,n^c-1\}$内的`n`个整数集合。

### 11.1 基于比较的排序
本节，我们展示三个排序算法：归并排序，快速排序和堆排序。它们使用一个数组`a`做参数并在$O(n\log n)$(期望)时间内将`a`的元素以非降序排序。这些算法都是 _基于排序的(comparison-based)_。第二个参数`c`，是实现了`compare(a,b)`方法的`Comparator`。这些算法不关心要排序的数据类型；它们对数据要执行的操作只是使用`compare(a,b)`方法进行比较。回忆下，1.2.4节中介绍了，如果`a<b`返回一个负数，如果`a>b`返回一个正数，如果`a==b`返回0。

#### 11.1.1 归并排序
_归并排序(merge-sort)_ 算法是递归分治(recursive divide and conquer)的经典例子：如果`a`的长度至多是1，那么`a`就是排好序的了，所以我们就什么也不用做。否则，我们将`a`二等分，`a0=a[0],...,a[n/2-1]`和`a1=a[n/2],...,a[n-1]`。我们递归地排序a0和a1，然后合并(现在已经排好序的)`a0`和`a1`从而得到了完整排好序的数组`a`:
```Java
<T> void mergeSort(T[] a,Comparator<T>c){
    if(a.length<=1)return;
    T[] a0 = Arrays.copyOfRange(a,0,a.length/2);
    T[] a1 = Arrays.copyOfRange(a,a.length/2,a.length);
    mergeSort(a0,c);
    mergeSort(a1,c);
    merge(a0,a1,a,c);
}
```
图11.1展示了一个例子。

![figure11.1.png "mergeSort(a,c)的执行"](figure11.1.png "mergeSort(a,c)的执行")

相比于排序，合并两个以及排好序的数组`a0`和`a1`相当容易。我们一次添加一个元素。如果`a0`或者`a1`为空，那么我们就从另一个(非空)数组中添加下下一个元素。否则，我们从`a0`和`a1`中下一个元素中选择最小的一个添加到`a`中：
```Java
<T> void merge(T[] a0,T[] a1,T[] a,Comparator<T> c){
    int i0 = 0,i1 = 0;
    for(int i = 0;i < a.length;i++){
        if(i0 = a0.length){
            a[i] = a1[i1++];
        }else if(i1 = a1.length){
            a[i] = a0[i0++];
        }else if (c.compare(a0[i0],a1[i1]) < 0){
            a[i] = a0[i0++];
        }else{
            a[i] = ai[i1++];
        }
    }
}
```
注意到`merge(a0,a1,a,c)`算法在`a0`或者`a1`中有一个跑完前执行至多`n-1`次比较。

![figure11.2.png "归并排序递归树"](figure11.2.png "归并排序递归树")

为了理解归并排序的运行时间，最简单的方式是以递归树的方式看待。假设现在`n`是2的幂，这样$n=2^{\log n}$，并且$\log n$是一个整数。参看图11.2。归并排序将排序`n`个元素的问题转为了两个问题，每个排序`n/2`个元素。这两个字问题分别又被转为两个问题，一共四个子问题，每个大小是`n/4`。这4个子问题又变成8个子问题，每个大小是`n/8`，依此类推。在这个过程的底部，一共有`n/2`个子问题，每个大小是2，转换为`n`个问题，每个大小是1。对于每个大小是$n/2^i$的子问题，花费在合并和拷贝数据的时间上是$O(n/2^i)$。由于这些$2^i$个子问题大小是$n/2^i$，那么花费为问题大小是$2^i$的总时间，不包括递归调用，是：
$$2^i\times O(n/2^i) = O(n)$$
因此，归并排序花费的时间总和是：
$$\sum_{i = 0}^{\log n}O(n)=O(n\log n)$$
下面定理的证明基于上面的分析，但是它仔细的处理的当`n`不是2的幂的情况。
__定理11.1__ `mergeSort(a,c)`算法运行时间是$O(n\log n)$并且最多执行$n\log n$次比较操作。

通过对`n`进行归纳证明。基本情况是，当`n=1`，它是一般的，当数组的长度是0或者1时，这个算法简单的返回而不执行任何比较。

合并两个总长度是$n$的已排序列表最多需要$n-1$次排序操作。及$C(n)$是对一个长度`n`的数组`a`执行`mergeSort(a,c)`操作需要执行的最大比较数。如果`n`是偶数，那么我们应用递推假设到两个子问题并获取：
$$\begin{aligned}
    C(n)&\le n-1+2C(n/2)\\
    &\le n-1+2((n/2)\log(n/2))\\
    &=n-1+n\log(n/2)\\
    &=n-1+n\log n - n\\
    &\lt n\log n.
\end{aligned}$$
(注：$C(n)$表示对长度为`n`的数组`a`进行归并排序需要执行的最大比较次数。根据上面归并排序的算法，可知：问题会拆成两个$n/2$的子问题，它们的比较次数是$C(n/2)$一共是$2C(n/2)$，以及最后一次归并两个总长度是`n`的已排序的数组最多只需要`n-1`次比较)

当`n`是奇数时，情况稍微有点复杂。针对这个情况，我们使用两个很容易验证的不等式：对于任意$x\ge 1$都有
$$\tag{11.1} \log(x+1)\le \log(x)+1$$
以及对于任意$x\ge 1/2$都有
$$\tag{11.2} \log(x+1/2)+\log(x-1/2)\le 2\log(x)$$
不等式(11.1)来自于这个事实$\log(x)+1=\log(2x)$，而不等式(11.2)来自于这个事实$\log$是一个凸函数。有了这些工具，对于奇数`n`，
$$\begin{aligned}
    C(n)&\le n-1 + C(\lceil n/2 \rceil) + C(\lfloor n/2 \rfloor)\\
    &\le  n-1 + \lceil n/2 \rceil\log(\lceil n/2 \rceil) + \lfloor n/2 \rfloor\log(\lfloor n/2 \rfloor)\\
    &=n-1+(n/2+1/2)\log(n/2+1/2)+(n/2-1/2)\log(n/2-1/2)\\
    &\le n-1+n\log(n/2)+(1/2)(\log(n/2+1/2))-\log(n/2-1/2)\\
    &\le n-1 + n\log(n/2)+1/2\\
    &\lt n+n\log(n/2)\\
    &=n+n(\log n-1)\\
    &=n\log n.
\end{aligned}$$
#### 11.1.2 快速排序
_快速排序(quicksort)_ 算法是另一个经典分治算法。跟归并排序不同，归并排序是在解决两个子问题后归并，快速排序在前面就完成了全部工作。

快速排序描述起来很简单：从`a`中随机挑选一个 _支点(pivot)_ 元素，`x`；把`a`划分为小于`x`的元素集合，等于`x`的元素集合和大于`x`的元素集合；并，递归的在这个分区中排序第一个和第三个集合。图11.3是一个例子。

![figure11.3.png "quickSort(a,0,14,c)的执行"](figure11.3.png "quickSort(a,0,14,c)的执行")

```Java
<T> void quickSort(T[] a,Comparator<T> c){
    quickSort(a,0,a.length,c);
}
<T> void quickSort(T[] a,int i,int n,Comparator<T> c){
    if(n<=1) return ;
    T x = a[i+rand.nextInt(n)];
    int p = i-1,j=i,q=i+n;
    // a[i..p]<x,  a[p+1..q-1]??x, a[q..i+n-1]>x 
    while(j<q){
        int comp = c.compare(a[j],x);
        if(comp<0){//移动到数组开头
            swap(a,j++,++p);
        }else if(comp>0){
            swap(a,j,--q);//移动到数组尾部
        }else{
            j++;//保留在中间
        }
    }
    //a[i,...,p]<x,a[p+1,...,q-1]==x,a[q,...i+n-1]>x
    quickSort(a,i,p-i+1,c);
    quickSort(a,q,n-(q-i),c);
}
```
所有这些都是原地完成的，因此，不需要复制已排好序的子数组，`quickSort(a,i,n,c)`方法只排序子数组`a[i],...,a[i+n-1]`。初始的，这个方法的调用参数是`quickSort(a,0,a.length,c)`。

快排算法核心就是原地分区算法。这个算法， 不使用额外的空间，交换`a`的元素并计算索引`p`和`q`，使得：
$$a[i]\begin{cases}
    \lt x \text{ 如果$0\le i \le p$}\\
    = x \text{ 如果$p\lt i\lt q$}\\
    \gt x \text{ 如果$q\le i\le n-1$}
\end{cases}$$
这个分区操作，代码中是通过`while`循环完成的，通过迭代的增加`p`和减少`q`维护开始和最后的条件。在每一步，位于位置`j`的元素要么移动在前端，要么移动到后端并留在那里。前两种情况，`j`是增加的，而在最后的情况，`j`不会增加，因为位于位置`j`的新元素还没没有被处理。

快速排序和7.1节介绍的随机二叉搜索树密切相关。事实上，如果快速排序的输入由`n`个不同的元素组成，那么快排递归树就是随机二叉搜索树。为了证明这个，回忆下当构造一个随机二叉搜索树时，我们做的第一件事是挑选一个随机元素`x`然后让它作为树的根。在这之后，每个元素最终都会跟`x`进行比较，小的元素会进入到左子树而大的元素会进入到右子树。

在快速排序中，我们随机选择一个元素`x`并立即将所有值跟`x`进行比较，把比它小的元素放到数组的开头，把比它元素放到数组末端。然后快速排序递归排序数组的开头和数组的尾部，而随机二叉搜索树递归地插入小的元素到根的左子树中，插入大的元素到根的右子树中。

随机二叉搜索树和快速排序的上述的相似性意味着我们可以转换引理7.1为对快排的声明：
__引理11.1__ 当用快排排序一个包含了整数`0,...,n-1`的数组，元素`i`与支点元素的期望比较次数最多是$H_{i+1}+H_{n-i}$。

简单的对调和数相加给出了下面跟快排运行时间相关的定理：
__定理11.2__ 当用快排排序一个包含了`n`个不同元素的数组，执行比较的期望次数最多是$2n\ln n+O(n)$

$\text{证明}$ 设$T$是快排排序`n`个不同元素需要执行的比较次数。使用引理11.1以及期望的线性性质，我们有：
$$\begin{aligned}
    \mathrm{E}[T]&=\sum_{i=0}^{n-1}(H_{i+1}+H_{n-i})\\
    &=2\sum_{i=1}^{n}H_i\\
    &\le 2\sum_{i=1}^{n}H_n\\
    &\le 2n\ln n+2=2n\ln n+O(n)
\end{aligned}$$
定理11.3描述了如果排序的元素都是不同的情况。当输入数组`a`包含了重复元素，快排的期望运行时间不仅不会糟糕，甚至会更好；任何时间一个重复元素`x`被选为支点，所有出现的`x`都会聚集在一起而不会分到两个子问题中。
__定理11.3__ `quickSort(a,c)`方法运行期望时间是$O(n\log n)$并且他执行的比较的期望次数最多是$2n\ln n+O(n)$。

#### 11.1.3 堆排序
_堆排序(heap-sort)_ 算法是另一个原址排序算法。堆排序使用了第10.1节描述的二叉堆。回忆下`BinaryHeap`数据结构使用单个数组表示一个堆。堆排序算法将输入数组转换为一个堆，然后重复提取最小值。

更具体的说，这个堆在数组的位置`a[0],...,a[n-1]`中存放了的`n`元素，并且在根`a[0]`处存放了最小的值。在转换到`BinaryHeap`后，堆排序算法重复交换`a[0]`和`a[n-1]`，降低`n`，然后调用`trickleDown(0)`，这样`a[0],...,a[n-2]`就有变成了有效的堆表示。当这个过程结束时(由于$n=0$)，`a`中的元素是以降序顺序存储，因此反转`a`就可以获得最终排序[<sup id="content1">1</sup>](#1)。图11.4展示了`heapSort(a,c)`的一个例子。
```Java
<T> void sort(T[] a,Comparator<T> c){
    BinaryHeap<T> h = new BinaryHeap<T>(a,c);
    while(h.n>1){
        h.swap(--h.n,0);
        h.trickleDown(0);
    }
    Collections.reverse(Arrays.asList(a));
}
```
堆排序中的关键例程(subroutine)是将数组转换到堆中的构造器。通过重复调用`BinaryHeap`的`add(x)`方法可以很容易的达到$O(n\log n)$的运行时间，但是我们可以通过一个自底向上的算法做的更好。回忆一下，在二叉堆中，`a[i]`的孩子存放在`a[2*i+1]`和`a[2*i+2]`处。这意味着元素$a[\lfloorn/2\rfloor],...,a[n-1]$都没有孩子。换句话说，$a[\lfloorn/2\rfloor],...,a[n-1]$每一个都是大小为1的子堆。现在，倒回来工作，我们可以对每个$i\in\{\lfloorn/2\rfloor,...,0\}$调用`trickleDown(i)`。这样做的话，由于我们我们调用`trickleDown(i)`的时候`a[i]`的两个孩子都是子堆的根，所以调用`trickleDown(i)`让`a[i]`成为自己自己拥有子堆的根。
```Java
BinaryHeap(T[]a,Comparator<T> c){
    this.c = c;
    this.a = a;
    n = a.length;
    for(int i = n/2-1;i>=0;i--){
        trickleDown(i);
    }
}
```
这个自底向上策略有意思的地方就是他比调用`n`次`add(x)`要更高效。为了证明，注意到，对于其中$n/2$个元素，我们什么工作都没有做，对于其中$n/4$个元素，我们对以`a[i]`为根的子堆调用`trickleDown(i)`(这些子堆的高是1)，对于其中$n/8$个元素，我们是对高度为2的子堆调用`trickleDown(i)`，以此类推。因为`trickleDown(i)`的工作正比于以`a[i]`为根子堆的高度，这意味着全部工作完成至多：
$$\sum_{i=1}^{\log n}O((i-1)n/2^i)\le \sum_{i=1}^{\infty}O(in/2^i)=O(n)\sum_{i=1}^{\infty}i/2^i=O(2n)=O(n)$$
由于意识到，根据期望的定义，和$\sum_{i=1}^{\infty}i/2^i$等于我们抛掷硬币首次正面朝上的期望并应用引理4.2(the sum $\sum_{i=1}^{\infty}i/2^i$ is equal,by definition ofexpected value,to the expected number of times we toss a coin up to and including the first time the coin comes up as heads and applying Lemma4.2)，从而得到了倒数第二个不等式。

如下定理描述了`heapSort(a,c)`的性能。
__定理11.4__ `heapSort(a,c)`方法运行时间为$O(n\log n)$并且最多执行$2n\log n+O(n)$次比较。

$\text{证明}$ 这个算法执行的有三步：(1)转换为一个堆，(2)重复的从`a`中提取最小的元素，(3)反转`a`中的元素。我们已经证明了步骤一花费了$O(n)$的时间并执行$O(n)$次比较。步骤(3)的时间开销是$O(n)$并且不执行比较。步骤2调用了`n`次`trickleDown(i)`。第$i$次对一个堆大小$n-i$的堆进行调用最多执行$2\log(n-i)$次比较。对$i$求和有：
$$\sum_{i=0}^{n-i}2\log(n-i)\le\sum_{i=0}^{n-i}2\log n = 2n\log n$$
将三步中全部比较次数加起来就证明了这个定理。
#### 11.1.4 基于比较的排序的下界


[<sup id="1">1</sup>](#content1)这个算法可以替换为重定义的`compare(x,y)`函数，使得堆排序算法直接按照升序存放数据。